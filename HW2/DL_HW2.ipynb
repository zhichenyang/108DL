{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.\n",
    "Please load ‚Äòdata.mat‚Äô into your Python code, where you will find $ ùë•, ùë¶ ‚àà ùëÖ^{1001} $.\n",
    "Please use the loss function (L1 Norm) below to find the curve ùë¶ = $ùúÉ_ùüé + ùë•ùúÉ_ùüè + ùë•^\n",
    "2ùúÉ_ùüê$\n",
    "that best approximates ùë¶ based on ùë•. (upload your source code to moodle, and show the\n",
    "results, including a plot where the line is overlaid over the given data in the report)\n",
    "ùêøùëúùë†ùë† ùêπùë¢ùëõùëêùë°ùëñùëúùëõ: ùëì(ùúΩ) =$ ‚àë|ùë¶_ùëñ ‚àí (ùúÉ_ùüé + ùë•ùúÉ_ùüè + ùë•\n",
    "^2ùúÉ_ùüê)|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a, b, c = 5.5811439250000054 0.2967090000000458 1.0283999999999953\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data = loadmat('D:\\DL\\HW2\\data.mat')\n",
    "# print(data)\n",
    "x,y = data['x'], data['y']\n",
    "\n",
    "epoch = 2000\n",
    "learning_rate = 0.0003\n",
    "a=1\n",
    "b=0\n",
    "c=0\n",
    "plt.plot(x,y)\n",
    "for i in range(epoch):\n",
    "    y_pred = a*x*x + b*x + c\n",
    "    lad = np.sign(y - y_pred)\n",
    "    d_a = sum(-lad*x*x)\n",
    "    d_b = sum(-lad*x)\n",
    "    d_c = sum(-lad*1)\n",
    "    \n",
    "    a =a- learning_rate*d_a\n",
    "    b =b- learning_rate*d_b\n",
    "    c =c- learning_rate*d_c\n",
    "print('a, b, c =',a[0],b[0],c[0])\n",
    "y_pred = a*x*x + b*x + c\n",
    "plt.plot(x,y_pred,'r-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.\n",
    "In ‚Äòtrain.mat,‚Äô you can find 2-D points $X=[x1, x2]$ and their corresponding labels $Y=y$.\n",
    "Please use logistic regression $‚Ñé(ùúΩ) = \\frac{1}{1+ùëí^{‚àíùúΩ^{ùëá_ùë•}}} $ to find the decision boundary\n",
    "(optimal $ùúΩ^‚àó$ ) based on ‚Äòtrain.mat.‚Äù Report the test error on the test dataset ‚Äòtest.mat.‚Äô\n",
    "(percentage of misclassified test samples) \n",
    "Hint: you can use ‚ÄúLogisticRegression‚Äù in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: [[-1.93360539  3.27369815]]\n",
      "Interception: [0.38541225]\n",
      "misclassified 0.033333333333333326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhich\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15675f08518>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAFaCAYAAADowK8UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3dd3ydZf3/8dd1VnabNKNpm6ZpRhelhU5AQKagIDgQFUEU+fFFZItsRJGNyCizLJkqMgRBEBARldEWhLZQ2qRJmqQzaZNmnn39/jhpyGnSQZv0JHfez8eDB811n5x8bmjyzn3d1319jLUWERERGdxciS5AREREdp8CXURExAEU6CIiIg6gQBcREXEABbqIiIgDeBJdwO7IycmxRUVFiS5DRPaYKIHAOoLBdcDnT+gY48bnG43PlwuYhFUn0t8++OCDBmttbm/HBnWgFxUVsWjRokSXISL9zFpLff2zrFz5cwKBtXHH8vN/THHxjfh8eQmqTmTPMcas2taxQR3oIuJ8bW2fUF5+Lk1Nb8aNZ2TMpqxsHsOGzU1QZSIDiwJdRAakcHgz1dW/oq5uHhDpGvd6cykuvoH8/B9jjJYBiWyhQBeRAcXaKOvWPUZl5SWEQhu6HXEzZszPKCr6NV5vZsLqExmoFOgiMmA0Ny+iouIcmpvfixvPzDyE0tI7SU/fO0GViQx8CnQRSbhgsJ6qqstZu/Yhuq9eT0oqoKTkt+TmnogxWr0usj0KdBFJmGg0zJo191FdfRXhcFPXuDE+xo69iHHjLsftTktghSKDhwJdRBKiqeltysvPpq1tSdz4iBHHUFp6O6mppQmqTGRwUqCLyB7l99dRWfkLNmz4Y9x4cnIJZWV3kJ19TIIqExncFOgiskdEowFqa29j1apriUbbusZdrlTGjbuCgoILcbuTE1ihyOCmQBeRfrdx49+oqDifjo7yuPHc3O9SUnILycljE1SZiHMo0EWk33R0rKSi4nw2bnwpbjwtbSqlpfPIyjokMYWJOJACXUT6XCTSxqpVN1BbewvWBrvG3e7hjB//G0aP/ikul378iPQlfUeJ9JP2QJhI1OL1uEj2uhNdzh4Ra6LyZ1auvIhAoLbbEUN+/mkUF1+vJioi/USBLtLHguEIjW1B7v9HBdUNrcwqzuZHBxWT4nM7enOU1talVFScS1PTP+PGMzLmUFZ2F8OGzU5QZSJDgwJdpI+1BSKccMe/afGHAfiwupF/LdvAY2fuT5IDr9RDoSaqq3/F6tV30bOJyk3k55+qJioie4ACXaQPBcIRnnqnqivMt1i+tplP12xm33EjElRZ34s1Ufk9lZWXEgrVdzviZsyYsykq+pWaqIjsQQp0kT4UiVjWb/b3emxdUweM28MF9ZPm5oWUl59NS8uCuPHMzEM7m6hMTVBlIkOXAl2kDyV73Rw5dRQvfrg6btztMuxfmpugqvpOMLiBysrLWbfuobjxWBOVW8nN/Y6j1wmIDGQKdJHd1OYPY7G4jCE1ycPskmy+M2cszy6sJWoh2evi8uOn4vMM3vvIsSYq91JVdRWRyOau8VgTlV8wbtxlaqIikmAKdJFdFAhH2NQaZN5ry1m5vpXp4zL52RETSE/2cMFXJ3PWkRNY3dhBSV461kJq0uD8dmtq+hfl5ef0aKKSnX0sJSW3qYmKyAAxOH/CiAwAgVCUE+/8fDX78rXNvLOigWfPO4jUJA+pSR6y0pISXOWu8/vrWLnyIurr/xQ3npJSSmnpHWRnfy1BlYlIbxToItsRm04HA6Qlf/7tEopE+fP7q3qsZq/b1M67FQ0cMnnkni20D8WaqPyus4lKe9e4y5XGuHFXMnbsBbhcg/cXFRGnUqCL9CIUjtLYHuSOVz9j2ZpmJo8exnlHTSIrzYvX4yYStdS3BHr93Prm3le5DwYbN77c2USlIm48L+97FBffQnJyQYIqE5EdUaCL9CIUjfK9u/7DptbYPuSVG1p5p7yBl39xCF5iq9m/Nn00f3x3VdznuQwcOiU/ARXvnvb2CioqzmfTppfjxtPS9qasbB6ZmV9OUGUisrMG77JbkX5ireWVj9Z0hfkWjW1BXvloDdZaAMryMzjz8DK87ti3UVqSh19/exqpST13g2v1h2gLhGkPhHscS6RIpI3KystZuHCvuDD3eDIpLZ3HzJkfKsxFBokBd4VujHEDi4DV1tpjE12PDD0WaGjdxnR6SwBrwRhI8Xn44YHjOeXA8azf7Gd0VgrWWlJ8n39bdQQj1DS0Me+15dRsbGNWcTbnHTWRjGQvLlfinteONVF5urOJSl23I4ZRo05n/Pjr8PkG/3PzIkPJgAt04DxgGTAs0YXI0OQyhq9NH829b5T3OPa1fUbHBfGWR9GK89J7fa/GtgCn3PcOwXAUgJqN7fyvehN/PPtAklyJ2de9tXVJZxOVt+LGMzLmdjZRmZWQukRk9wyoKXdjTAFwDPBgomuRoS07I4krjt+LVF8sdFN9bq44fi9yMmKru5s7grQHwjR3BLf5Hh3BMI//p6orzLeoqm/jk9Wbt/FZ/ScUaqK8/FwWLdo3Lsy93jwmTnyYGTPeUZiLDGID7Qr9duBiIGNbLzDGnAGcAVBYWLiHypKhJtXn4Zh9x/D1fQuob/GTm5FMFAsWKje0cNsry6lY38zeYzO54KuTGZHqI8kXf8UdtZbmjlCv79/c3vt4f7A2ytq1D1NVdRmhUEO3I24KCs6lqOhqPJ7he6weEekfAybQjTHHAhustR8YYw7Z1uustfOB+QCzZs2ye6g8GYJSO++Fj83+fEvTprYgp9z7Lm2di9vWNq1jUdUmXr7okF4//9h9x/DyR2vixpO9LuaUZPdf4d00Ny/obKKyMG48M/MwysruJC1trz1Sh4j0v4E05f4l4DhjTDXwR+AwY8wTiS1JhqJWfwh/KEKrP/4qOhiO8MyCmq4w32JTa5A3lq6LG4tGLW2BMPuMG8Fz5x/E4XvFNprJyUjijlNm9XsDk2BwPZ99dhoffjg3LsyTksYyZcqfmT79DYW5iMMMmCt0a+1lwGUAnVfoF1lrT05oUTKkBMMR1m/2c8vLy/h09WYm5Gdw0TGTGZOVSpLXTdRCi38bU+jdptY7ghEq1rdwx6ufUd3QxoyiLC47bi+uOH4qaZ2L6JK8/bMgLhoNsWbNPVRV/ZJIpLlr3JgkCgsvprDwUtzu1H752iKSWAMm0EUSLRyx/OCed7rCuaElwCn3vssrFx9KktdNstfN1/ct4NF/V8V9nttlOGra6K6PG9sCnDb/PUKR2GK415asY3FNEy9c+OV+C3KAxsZ/Ul5+Du3tn8SNZ2cfT2np70hJKe63ry0iiTcgA91a+xbwVoLLkCHm1cVrOGRyHt/dbxxjs9NY09jOMwtqeX5RLSd/aTxul2FUZjJXfmMqd7z6GS3+MCPSfVx23F4ke2N3r/yhCE++U90V5lus2+zng6pNHDCh75/t9vtrOpuo/DluPCVlQmcTlaP7/GuKyMAzIANdJBFKRmYwefRw7nxtOZ/WbWbCqGGc/ZUJAJ27wxncbhcHT8rj6Gmj2NgaIDs9iUAo0tXrPGrtNneD2/re++6KRPzU1d3KqlXXEY12dI27XGkUFf2SgoLzcbl8ffo1RWTgUqCLdCrJS+erN/+zq4PawsqNnPnwAv72i0PxdG7v2h4Ic9ytb+F1u8jJSGL9Zj8et4tXLzkUH7GV7d+cNZbnF9XFvXey182X+vDqvKHhJSoqzsPvr4wbz8s7iZKSm0lKGtNnX0tEBoeBtMpdpM+0+sOEIlHaA2HCW01/b81aSzAc4dXFa3u0Q+0IRvjLoloiUUs4EuWZBTX4Q1Fa/GGq6ttoD0Zo7gjxj26r3MvyM7j42MlkdLZbHZ2Vwt0/mk1fLGxvby9n8eJjWLr063FhnpY2jX32eZspU55UmIsMUbpCF0cJR6JsbA1y3QtLWVS5kbHZaZx31ET2LcqK22N9i0AowpqmDj5e1djjMbUtOkIRrLVYC+3BSK+v6T6e0nmV/u05hbQHIqT63BgDPs+uL4gLh1upqbme2tpbsfbz3ek8nkzGj7+WUaP+D5dL384iQ5mu0MVRIlHLqfe9w9ufbaA9GGH52mbOfnQhaxo7tvn6H977Ds8sqOGIqaPwbNUwxWXgGzML8LhdeD0uvjlrbI8rbY/bcNTeo+LGUnwekjxustJ8JHnduxzm1lrWr/8DCxZMoqbmhm5hbhg16gzmzClnzJifKcxFRIEuzvJxTSPrNvvjxqIWnnq3mvZgz0VpbyxdR4s/zNK6zZSva+Hmk/Ylf3gyLgNnHFrCG5cdTv7wFNoDYSLRKLkZSVx/4j5de7qPzkzhzh/O6pfH0VpbF/PRR4ewbNlJBIOru8aHDdufmTMXMnHi/fh8OX3+dUVkcNKv9eIoWzdC2SIUjmJ72Sg4EP58qnxjq5/9S3P587kHEbWWuk3tnPf4ByxbvZnJY4Zz6denUDIyg0OnjOSwvUYSDEXxeVy7PZ3eo9ZQI9XVv2T16nuAz8/H6x1JScnNjBx5Msbod3ERiaefCuIos4qzGZbi7TH+7dmFXbu0dXfUtNH4PC6K89I5ZHI+J9z5b858eAGBUJSfPPA+S2qbiFjLktomfvLAewRCEZK9bpI8bjJSvLs1nb41a6OsWfMACxZMYPXqu9gS5sZ4KCi4kLlzl5Of/0OFuYj0ytjeLlsGiVmzZtlFixYlugwZQALhCFUbWrnyz4upWN9CVpqPs44o49h9x+Bzu+gIRUhL8uAPRXGZ2D3qVn+YFJ+HtGQP65o6qG5oZcWaFja1BfnO3ELGjEhlTWM7T79XQ94wHyfMGUfYWlJ9HtoCYZI8Bo9790J98+b3KC8/m9bWD+LGMzMP72yiMmW33l9EnMEY84G1ttc+x5pyF0dxAbkZSdx32hzcLoPP46K+2U/UWqoa2rj2+aV8VNNIUW4aFxw9iZnjR1DfEuC6Fz5gad1mSkdm8NuT9iUzxcdmf4ifP/Uhn61pZtLoYVzw1UmU5KXzUU0jN7+0jIr1LUwtGM7lx0+lKCeN1F5mAHYkGFxPZeWlrFv3+7jxpKRCSkt/R07Ot/q9kYuIOIOu0MVR/KEIx/72LTa1Bhie6qMtEKYsP4MHT5/LUTf9M66JSlFOGo+fdQBH3fhm3GNnx80cwwVHT+bom94k0O2e/NySbH797Wkce+tbhCOff9+k+ty8dulhpCf3nOrflmg0xOrVd1Fd/atemqhcQmHhJWqiIiI96ApdhoyPqhtpaAkA0NgWe8Tr+/uP41+fbYgLc4ADJ+bx6sdrejxbnj88hRc/qIsLc4ADynJ5dmFNXJhD7Bn0Vxev4YQ543aqxsbGf1Befi7t7Z/GjffWRCXi92PcbozLRcTvx5OWtvXbiYgACnRxGEvPGSdjTK8r3I2h93Fie7L3dmBbE1rR7W9GB2xpovJz6uufiRtPSZlAWdmdjBhxVNx4pKODtX95kdpHHyPU1ETW3DlM/OWVeDMzMbt5z15EnEfLZcVRZhSNICstviHJ0++t4suT8xi+1ZT4f1ds4Ojpo0ne6hnyd8obOG5GAV53/LfHu+UNfGv22B6bzyR7XXx1+mi2JRLxU139GxYsmBQX5m53OsXFNzN79pIeYR6NRNj07ntU3n4HocZGsJbG995n8c/OJRrqfUc7ERnaFOjiKMYYHj5jP6aNzcQYOPPwUu784Sw8LsNrlx3GDd/dh7QkD2OyUvjp4RNwGbj/J3OYkJ8BQGF2Gj8+uBh/KMJtJ8+gJC8diDVuOf3QEoaleLnt5JkUZsemvifkZ3D/aXNxuXouXLPW0tDwAgsXTqG6+pdxHdHyck9i5rSPGDvmwl47okU7Olj73PM9xturqgis30C4o4NdXf8SaW/HhsNEw2HCbW279B4iMvBoUZw4TjRq8YciGAO1G9u5+tnFLFvTzMjhyZx31EQOmTwStys2DZ/scxMKRwhHLR6XixZ/iGcX1vLQWys55cDxfGduIVmpPiJRi9tt8LpdBEIRLOBxGYKRKF6XwbvVs+jt7cspLz+Pxsa/x40nRcZj/ziK8GJLxl5TmHj1VSSPGoXLFx/q4ZZWPr38CpoWLOxxfvv+/iHWv/J3Ck895QtPv0f8firn3cX6v76MDYfJPuTLTLjiMt2bFxkktrcoTlfo4jgul+l6hOwnD7zHsjWxVeTrN/u58s8fU7upnSSvm2RfLAi9HjcpPg8doQhfu+Wf3P36CvyhCA/8s4JjbnmLzR1Bkn3urin4JK+bZK8bj9tFqs8TF+bhcAsrV17CwoV7x4W5xzOCgtQrCF4xkvDi2C/RLZ98ysdnntXrlbY7NYXR3/5Wj/HUkmKS8vJY++xzLD7nvC80/R7p6KD2sSdY+8xzRAMBbCRCwz/eZPk11+pKXcQBFOjiOOFIlGA4wnsVDV3tUF0GTj+khL9fchijs1LwB8N0BCN0BMMEQhHaA2F8HhcPnL4fk0cPA2JtUO87bQ5pSTt+HC3WROVJFiyYSG3tzVi7JWgNo0efycy9/0f4ZS/Gxk/NhzY10rxkaY/3M243WXPnUHLRhfhycsDlYsSXDmDqb2+h6t77sOEw7SsrCTZsjPu8SHs70VCIaCBAuK2t65eFcHs7xuOh4OST2Pf3D5F1wP5dn7Px7X9jPFofKzLY6btYHCUQilDd0MYbS9dSMjKja/yy46ZSlJvG/z28gB8eOJ78zBRu/OsnVNe3kTcsmQuOnsTBk3KZMmYYD52xHyleN/5QBK/bhce9/d97W1s/prz8HDZv/nfc+LBh+1NWdhcZGTMIt7VhXL2/j2sbW8e6U1LIP+7rjDr+OIzbTctny1l52x1sfPvtrteYbrVF/H6q7n+Adc//hWgwSNacOUy65mpcKSlU3XkX617+GzYcZsQB+zPh8kspv+EmNv33HYwx2rxGxAF0hS6OYoH/9+D7PLewlgPKcslK81EwIpXDp47k3McWEbWWAyfmcf7ji6iuj00zb2j2c/mfP2J9cwC3KzaNbowhxefZbpiHQptYseJnLFo0Iy7Mvd6RTJr0GPvu+18yMmYA4ElLY/R3v8PWvVeTRo4kY8q2t3V1JyWB203Dv97mo9NOjwvzjCmT8WZmAhAJBFn74l9Z88c/YbxevFmZNL7/Pp9cfCnhllbW/uUFbDAI0Sib/vNfVlx7PUU//T8Aco84XCvnRRxAgS6DSiQSpSMYptUfIhiO9miJ+kHVJpo7QmxsDfLUO9Xcf9ocvrf/ON5etoGOYIT9S3P456fr8YfiHxy3Fp5bWEt7MIw/FL/RzNbC/nZW19zD+++XsWbN5x3RjPFQMPp8Zk79kNzME7Hh+NpSx41jyg3XkVJY2DmlPpfp8++FbVy5b+Fyuxmx//6UXnwRSSNHYrxecg47lKl33IYrKSk2nW5g5FePZr9XX2a/l15g1h+fYuYfnyQpNxcbDpFcMCbuPRvfX0BSbi5jfnASZZddokVxIg6gKXcZNILhCGsaO7jkjx+xfG0z6UkeTj24mJO/NJ6ULQvc3J9fAd/3j3LWNLZz1hET+HT1ZiDWG737a7rzug2vfLSG9GQPB03KI9XX89ujccNbLP/kDPymPG48c9hhZK39DmvO/StrGk8geWwBE6+6gvSJE3EnJ3e+yuDNyWb6fXfjzcykvboarMVGIrCDe9julGRGHnss+V8/FuPxEOnowJOWRsTvp/re+2ha9AHT7p7HqgceYt1LL2ODQYbPnMHEK6/AnZIC4a1+SXG5cCUnM+7002LHRWTQ0xW6DBrWwhkPvc/ytbFV662BMHe/voJ3y+uJdG7VNr0wi5HDk7s+58UPV3PZn/7XNf3+r2XrOWTKSIZv1WLV63bx9RkF/O3jNVz6p49oaA7EHQ8E1rFs2al8/Omh8WG+KQnXk1OYXPQMDX94N7YJDOCvrWPJOefHwprYormWTz7h49P/j/e+9nX+fcBBfHDSKXz807N3+vzdST5cPh/G5cKTlkY0GGTNs8+x5ulnGP2dE1j73POsfe752NQ6sPmDD1l21dUYjwf/unVx75V72KHYSARPqvaLF3EKBboMGhXrW9iwVdACPL+ojrZAmPZAGLfL8NiZ+3PQxDySvW4m5Gdw5Tf2prq+lftPm8P4vHReWFTHA6fPZW5JNsleN3uNGc6dP5zJyg0tfFC1KTb9vqiWUDhKNBqitvZ3LFgwgfXrH/v8i4YMvF6AuXU6LB5OwxtvkDV3Tlxd0UCATf/5LwCRtnbWvvBi1zFfXi6Tb7yOmU8+RqS9g4jfTyQQILS5mYjfT3Sr6XqIrVSPBgKEmluIdHQQDYbY8MqrAGTNmcOG197o8TktS5cSDQYpveQX+PJy8QzLYNQJ39Kz5yIOpCl3GTR8nt5//0z2ulhc08SnqzdzyoHFjByewg3fnU6y100wHCXJ6+Ltzzbwj0/Wc85XJlKcl06rP8R1J05neIqPtU0dPLuwhif/W931nqk+N5ub3qCy8nza25fFf8GlIzAvjcM0fj4T4EpO7nHPHMCVlNT5B4MrKbZ5jDstjen33sOGV15lxTXXEWlvJ6VoHBOuuIzmjxez/uVXmHzdb0gZW9C14UzE76f6vvms+8tfiAaCpE+ayN533t513IbDn3+t7ozB5fUy8mtfJf+Yr4Ex2FBI0+wiDqQrdBk0xmanUdrtUbQtvj27kNeXruOeN8pZUNlANGpJT/bGNn5J8uB2udi/LJd3y+s56e7/st/Vf+eIG97ktPnvEYxEOfned3j031WEo7FntvPT65mVfQlLlx4VF+apqZOYMv4ZPE9Piwtzz7AMco84nI3vvBNXl3fECLL2mxt7TWoqBd/7HrhcjDz2GFqWLWPVgw8RaW8HoKN6FZ9cdAmjvvVNwn4/i88+t6sTTDQUYv3Lr7DmT08TDcSm01s/W876v7/G6BO/A0DDv/7FqG8e3+O/TfZBB4Fx4U5KwuXz4fJ6cWuaXcSRtPWrDBrRqKXZH+Kmv37KOyvqyc9M5rQvl5A/PIX/99D7BMNRDp0ykmtOmEbGVo1YQuEo9S0BbvzrJ/yvehPFeen87MgJ5KQnEbGW2175jGWr13P85BfZJ+dJsJ/vu+52Z1BUdDVjxpyDDUZpr15F5e130Faxkoy9plDy8wtw+Xx01NSy6oEHaa+qZtj0aYw/+yyi/gBppSVdi9+aFy/BeDysfvrPbHzrXz3Ocdq9d5MxdS+aPvgQb0YGw6buRbi1laXnX9hjAxrPsAzmPPcMG157g/V/+xuTrvkVm955lzV/+jPh1lZyDj+U4p+dhY1GMS43ruSkbT4LLyKDg/qhiyO4XIbMVB9XfmMqbpehoSXAS/9bzdXPLiHY2bs8xefGRc9V7F6Pi9FZKVx/4j74PIZQxOIy4HYZohHLZUfVUrfqIgKBarp3YB058hSKi28iKWlUbCAZ0ieUsdett+DyeomGQriSkqie/yA2GKTs8ktJysmhvXoVNQ89QvZBB1L/+huMOGB/MqbuxfBZM4m0tW17yttGqfjtrYz+1jdJys///Nx7eX24uYXg5s24U5KYcsN1uFJSyJw9m9wjDsedmkrr8hV8fPa5tH7yKRl7TWGvW27Cm5WlUBdxKF2hy6AUCEU46e7/snJDa9eYy8BTP/sSk0YP3+n32VYTlfT0fSkru4vhww/YuXrWb2DBCSd2rTAH8OXkMPMPT7DoxO/jy8tj+v334OkM5tYVK/jw1NPwZWXhGT4c/+rVJI8ezfT77ub9476JOzWVOS88hzspCRuN0vj+Apaef2Hc1xw+Y1+m3HAd7x59TFyj9r3n3UHjggXUPf5k3Oszpk5l2l136P65yCC2vSt0BboMSlum32956VPeq2hgdFYqPztyAtMLM0np5fnxrYXDLaxadS11dbd123c91kSluPh6Ro06nag/BC5DqLEJb1YmRC3ulORe3y/i99NeVUXlvLtpr6pi+PTpFP30/2hcsJDsA7+ENzOTUNNmvCOysJEIxuUi3NyMKzmZ0MZN+HJziIZCVN19L+v/+hIA0+ffx/Dp02Lv39HBpnfepeb3jxHatInsgw5k3BmnEw0GaXx/Aav/9DThlhZyDjmE8WedyaLv/4DA2nU96tz/9VfxDhu2K//JRWQA0JS7OM6W6ffLj5uK222IRC3JXhfuHUwnb2miUll5McHg2u7vyOjRZzJ+/G/wekcQ6eig/h9vUnn7nYRbWvBkZFB8/rnkHnYY7tSeV7ju5GTSJ05kr5tvxFpLW3kFNY89QemF51P35FPUPfEU0UAAX24Ok379KzKmTGb1n55m9dPPYINBkkaOZOLVV5E+oYz1ne/Z/bEyd0oK2V8+mKz95mJDITZ/9DGf/OJSOmpWUXDyD9jrlpvwjRgRu1tgbe8L39xuXN4dN5oRkcFJN9NkUEtL9pDsdZPWuZp9e1paPuJ//zuIzz47JS7Mhw8/kJkzP2DChLvxekcAEGpsZMW11xNuaQEg3NLCimuvJ9TUuM33Ny4XnvR0Iq1tLDnvArIP/BLNi5dQ89AjRAOx5+eD9Q1sev99Nr37HnVPPNU1RR9Yv55PL7mMvKOPwjtiBOmTJvbYrtXl8eBOTqZ56Sd8eslltCxdSri5hep77mPlrbdhrcWTkoLxein4/vd71Jf3lSOx0WiPcRFxBl2hi+OFQhupqrqKNWvuZ8u+6wA+3yhKSm4hL++kuG5jNhpl/St/j7svHTtgWf+3Vyk87UfbXVjmzcpkzvPP4PL5WPm723scHz5tGute+GuP8XBLC82LlzDu9J+Q95UjMJ3PmHdn3G4yZ85gyo3XU/Po44Sbmsg+9BCKzji96964y+sl94jDwGVY/Yc/EWlvJ/crR1D4o1O7bUMrIk6jQBfHsjbCmjUPUFV1BeHwpq5xY7wUFJzPuHFX4fH0fK4dY2L3zHvhzcrs0TGtly/M2ueeJ3nMGDzp6T0OR/1+PBk9xwGS8nIZPmMGnl6m9bdwp6Qw4qADyZwzu+sXi60XurlTUsg76ivkHHpI7JcVYxTmIg6nKXdxpM2b3+GDD2ZTXv7TuDDPyvoKs2cvoaTk5t7DHDDGkHf0UXiGx6+W9wwbRt7RR+2wd3jLp59S89Aj1L/2OqO+cTxmq78EigsAABwNSURBVPvWmz9eTMHJP8C44/ugp02YQMq4cdsN8y1cHg+etDTcKSnbXLXu8njwpKbGXqMwF3E8XaGLowQCa6msvIT16x+PG09OLqKk5DZyco7fYSBDLAxnPPoIlXfOo3X5CtInTqD43LO3u6gs0t5ONBJhfef+6o3vL6Dt2Cqm3XUHNY88SkdtHZkzZzDuJ6dhfF6m338v1ffPx792LVlz5zD+rJ92beW6Rbi9HRsKEdq8OdY61ZgerxERAT22Jg4RjQapq7uTVauuIRJp6Rp3uZIpLLyUsWMvxu3+4s9fh9vaMMbEFpxtp5lJpMNP7WOP48vLxV9bS92Tf9hSAPlfj7U9TSksBLcLb+c0vI1GibR3gMtgoMfK9Ijfz4rrbqD+9TfAWny5Oex1y02kFRf3vm+7iDje9h5b05S7DHqbNr3OokXTqaz8RVyY5+R8i9mzl1FUdPUuhTnEHh1zp6busDNZYGMDG9/5L/V/f438bxyPa8sUdzTKuhdeZPmvf4M7ObkrzGHLqvi02LT4VmEeDYVY95cXqX/t9a7FecH6BpZe+ItdOg8RcT5Nucug1dFRzcqVF9LQ8HzceGrqJEpL5zFixBHb/NxIRwcYQ0ddHcn5+eBy7VJv8HBrbKe6aFs7+9x3L4GGBlqXfcb0e++m5pFHaa9ZRea++1J01pkY785/u0X9AerffLPHeGjTJtpra0kvLf3CtYqIsynQZdCJRDqorb2ZmpobiUb9XeOxJiq/YsyYc3C5tnOvu6OD+jf+QcWttxHt6MB4PBSc8gMKTz11mzvB9fo+7R3UPvYEdU8+FWtfmpJCyQXnMeKA/am66x7GfO87pBYX405K+uIdzgx4M7ex0l47vYlILzTlLoOGtZb6+udZuHAK1dW/igvzkSN/yJw5Kxg79sLthjlApK2dFdfdQLQj1lHNhsPUPvIoreXlX6ie1hXLqX30sa4+6NGODspvuAkAk5TEihtu6nU6fWd40tMp/PGPYKuV8FkH7I8nvffV+SIytOkKXQaFtrbPqKg4j8bG1+LG09NnUFY2b6ebqAA0vP3vnpvGAPV/f430CWU79YhXuL2d+jd6ToljLRvf+hdjTjyB4rPPwnh2/VsstWgc+9x/LzWP/J5gQwMjDj6IsT84Sc1VRKRXCnQZ0MLhZqqrr2H16juwNtw17vFkdzZR+QnGuLfzDj0ljcztddyXm7vTAWw8Hnw52b2/T14eqUVFuHYjzCG2OUzG1L2YdM2vYl/T68Wt1e0isg2acpcBydoo69Y9xoIFE6mru7VbmLsYPfos5s5dwejRZ3zhMAfImjWL5LEFcWOeYcMY9a1v7HQIu30+Rn3rm3i2up+dPLaArP3m7naYb2GMwZOejic9XWEuItulK3QZcFpaPqS8/Byam9+JGx8+/CDKyuaRnj59t97feDzMeOQhqh98mJbFi0kdP56iM8/4QrupRQIBghs3MeOJR1k1/0HaKyvJ2Htvxp1+Gh11q0kvKd7xe3R0EG5uIbBhPWllZbEuaSkpRDo6CDVtJrixgbTO1eza6U1EdkSBLgNGKLSRysorWLt2PvD5PW6fb3RnE5Xv79Qubzti3G48GRmMP/MMbDgC7i/+yJpxu9n0n/8Q6eig8Mc/wp2SQqilhcq77iHnkIN3GOgRv5/l11xLw5v/BMCVksKUG65j+D7TWXbFVWz6b+yXGXdaGpOv+w3D991HoS4i26VAl4SLNVGZ39lE5fP2pLEmKhcybtyVeDy9NzPZHbuzuMzl8TDqm99g4bdPpOahR7rGU8aNo+znF2z3c204zIbXXu8Kc4itkG+vrqa9qqorzAEibW0su+Iq9vvbS7tcq4gMDQp0Saimpv9QUXEOra0fxY2PGHE0paV3kJo6IUGV7ZjL52PmU4+z6oGHaKusZNi0aRT+6Ic9mrFsLeL3s/Ffb/cYz5g0ier5D/R8fVsb7ZUryZgypc9qFxHnUaBLQgQCa1i58mI2bHgybjw5uZjS0tvIzv56n0yv9yeXz4cvO5vx554NkQjG49mpq37jdpOUl9djPNTc3Os4gC87Z7frFRFn0yp32aOi0SA1NbewYMHEuDB3uVIoKvoNs2d/Qk7OcQM+zLvzpKbiycjY6Sl8d0oKY3/0Q1xbvb61vJzC036MKym+m1r2wQfjydBmMiKyfQPmCt0YMxZ4DMgHosB8a+0dia1K+tKmTX+nvPw8OjqWx43n5p5AScmtJCcXJqSuSHs7EX+A1uXLSS0ej3fYsH7fvMWbmcmsp56g5uFHYu1Tv3QAo7/1TQBmPvE4NY/8nkB9PdkHH0z+ccdqQZyI7NCAaZ9qjBkFjLLWfmiMyQA+AL5hrf10W5+j9qmDQ0dHVWcTlb/EjaemTqasbB5ZWYcnqLLYo2O1jz9JzSO/h2gUgPzjj6PkwvP3SIhu6aHuTkqK63MebmuDaBRXcvJ2e7CLyNCyvfapA+YK3Vq7Fljb+ecWY8wyYAywzUCXgS0Saaem5iZqa2/eqonKsM4mKmfvcN/1/haor6fmoYfjxta98CJ5R32FzJkz+v3ru1NT6W1rnB21axUR2dqACfTujDFFwL7A+4mtRHaFtZaGhuepqLiQQGBV3LH8/B8xfvwNJCXlJ6i6eJv+899exze+/TbD9p4ad9UsIjKQDbhAN8akA88C51trm3s5fgZwBkBhYWLuucq2tbUto6LiXBob34gbT0+f2dlEZf8EVda71KKiXsdTCsf16HQmIjKQDahV7sYYL7Ewf9Ja+1xvr7HWzrfWzrLWzsrN7b3Jhux54XAzFRUXsWjRtLgw93pzmDBhPjNnvj/gwhwgc+YM0spK48aSRuUz8mtH41Kgi8ggMmCu0E3sOaWHgGXW2t8luh7ZOdZGWb/+CVauvJhQaH23Iy7GjDmLoqJr8HqzElbfjhifj33m38+aZ59l88eLSZ84gYLvfw+jqXYRGWQG0ir3A4F/A0uIPbYGcLm19m/b+hytck+sWBOVs2lufjdufPjwgzubqExLUGVfXDQYJBoMqkWpiAxog2WV+3+AwbObyBAWDDZQVXUFa9c+QHwTlTGUlPyWvLzvDqqNYSC265sWwInIYDZgAl0Gvmg0zNq191NVdVWPJipjx/6cwsIr+qWJioiI7JgCXXZKU9O/KS8/h7a2j+PGR4z4KqWltw/oJioiIkOBAl22KxBY3dlE5am48VgTldvJzj520E2vi4g4kQJdehWNBqmru53q6muIRtu6xl2uFAoLL2fs2Itwu7W/uIjIQKFAlx42bnyViorz6OhYETeem3siJSW/JTl5bIIqExGRbVGgS5eOjkoqKi5g48YX48bT0qZSWnonWVmHJqgyERHZEQW6dDZRuZGampuxNtA17nYPY/z43zB69Fm4XPqrIiIykOmn9BBmraW+/llWrvw5gUBN3LH8/B9TXHwDPt/IBFUnIiJfhAJ9iGpr+4Ty8nNpanozbjwjYzZlZfMYNmxugioTEZFdoUAfYsLhzVRX/4q6unlApGvc682huPhG8vN/jDEDqmePiIjsBAX6EGFtlHXrHqOy8hJCoQ3djrg7m6j8ekA3URERke1ToA8Bzc2LKC8/m5aW9+PGhw//cmcTlb0TVJmIiPQVBbqDBYP1nU1UHqR7E5WkpAJKSn5Lbu6J2uVNRMQhFOgOFI2GWbPmPqqrryIcbuoaN8bH2LEXMW7c5bjdaQmsUERE+poC3WGamt6mvPxs2tqWxI2PGHFMZxOV0gRVJiIi/UmB7hCxJiq/YMOGP8SNJyeXUFp6Ozk5xyaoMhER2RMU6INcNBqgtvY2Vq26dqsmKqmMG3cFBQUXqomKiMgQoEAfxDZufKWziUp53Hhu7ncpKblFTVRERIYQBfog1NGxsrOJyl/jxmNNVOaRlXVIYgoTEZGEUaAPIrEmKjdQU3PLVk1UhjN+/DVqoiIiMoTpp/8gEGui8kxnE5XabkcM+fmnUVx8PT5fXsLqExGRxFOgD3DbbqIyh7Kyuxg2bHaCKhMRkYFEgT5AbbuJSl5nE5VT1URFRES6KNAHmFgTlUeprLy0lyYqZ1NU9Cu83syE1SciIgOTAn0AaW5eSHn5OT2aqGRmHkpp6Z2kp09NUGUiIjLQKdAHgGBwA5WVl7Nu3cP0bKJyK7m531ETFRER2S4FegLFmqjcQ1XVL4lENneNx5qo/IJx4y5TExUREdkpCvQEaWx8i4qKc2hrWxo3np39dUpLbyMlpSRBlYmIyGCkQN/D/P46Vq68iPr6P8WNp6SUUVp6B9nZX01QZSIiMpgp0PeQWBOV33U2UWnvGne50hg37krGjr0AlyspgRWKiMhgpkDfAzZufJmKivPp6KiIG8/L+z7FxTeTnFyQoMpERMQpFOj9qL29goqK89m06eW48bS0vSkrm0dm5pcTVJmIiDiNAr0fRCJtrFp1HbW1t2JtsGvc48mkqOg3jB59ppqoiIhIn1Kq9KFYE5WnWbnyIgKBum5HDKNG/YTx46/H58tNWH0iIuJcCvQ+0tq6hIqKc2lqeituPCNjbmcTlVmJKUxERIYEBfpuCoWaqK7+JatX30PPJio3kZ//QzVRERGRfqdA30WxJiqPUFl5GaFQfbcjbgoKzqWo6Go8nuEJq09ERIYWBfouaG5eQHn52bS0LIwbz8w8nLKyO0lLm5KgykREZKhSoH8BsSYql3U2UflcUtJYSktvIyfnW2qiIiIiCaFA3wnRaKizicrVWzVRSaKw8GIKCy/F7U5NYIUiIjLUKdB3oLHxn5SXn0N7+ydx49nZx3U2USlOUGUiIiKfU6Bvg99f29lE5em48VgTlTvJzj46QZWJiIj0pEDfSiTip7b2t9TUXE802tE17nKlUVR0FQUF56uJioiIDDgK9E7WWjZufImKivPx+yvjjuXlnURJyc0kJY1JUHUiIiLbp0AH2tvLqag4j02bXokbT0ub3tlE5aAEVSYiIrJzhnSgh8Ot1NRcR23t77ZqopLF+PG/YdSo/1MTFRERGRSGZFpZa9mw4U+sXHkRweDqbkcMo0adwfjx1+Lz5SSsPhERkS9qyAV6a+tiysvPZfPmf8WNDxu2P2Vl88jImJmgykRERHbdkAn0UKixWxOVaNe41zuSkpKbGTnyZDVRERGRQcvxgW5tlLVrH6aq6jJCoYaucWM8jBlzLkVFv1QTFRERGfS+cKAbY44ETgTuttZ+ZIw5w1o7v+9L233Nze93NlFZFDeuJioiIuI0u3KFfhbwY+BKY8wIYJ++KsYYczRwB+AGHrTW3rgr7xMMru9sovJI3HhSUiGlpb9TExUREXGcXQn0emttE3CRMeZGYHZfFGKMcQN3A0cCdcBCY8yL1tpPd/Y9otEQq1ffTXX11UQizd3eO4nCwksoLLxETVRERMSRdiXQX97yB2vtpcaYc/qoljlAhbW2EsAY80fgeGCnAr2x8c3OJirxL8/OPp7S0t+piYqIiDjaDgPdGPMo8P9s584r1toXuh+31s7ro1rGALXdPq4D5vZSzxnAGQCFhYX4/TWsXPlz6uufiXtdSsoEysruZMSIo/qoPBERkYFrZ57TqgXeNcYUdR80xkwzxjzch7X0dlPb9hiwdr61dpa1dtbw4WEWLJgUF+ZudzrFxTcze/YShbmIiAwZO7xCt9ZeaYx5D3jDGHMe4AXOBzKILWDrK3XA2G4fFwBrtvcJgcAaop8/Uk5e3g86m6iM7sOyREREBr6dvYf+NvAq8FdgA3CitfbtPq5lIVBmjBkPrAa+B5y0M5+Ynr4PpaXzyMw8sI9LEhERGRx2OOVujLkbWAK0ApOBN4FzjTF9ulzcWhsGzgb+DiwDnrbWfrL92tyUld3DzJmLFOYiIjKk7cwV+hLgImttR+fHJxljfg68Z4w5wVq7oq+Ksdb+Dfjbzr4+LW0qY8b8tK++vIiIyKC1M/fQ7+tl7FZjzP+IhW9pfxS2M4xx/M61IiIiO2WXu5FYa98EDu3DWkRERGQX7VZ7MWtt7Y5fJSIiIv1N/UJFREQcQIEuIiLiAAp0ERERB1Cgi4iIOIACXURExAEU6CIiIg6gQBcREXEABbqIiIgDKNBFREQcQIEuIiLiAAp0ERERB1Cgi4iIOIACXURExAEU6CIiIg6gQBcREXEABbqIiIgDKNBFREQcQIEuIiLiAAp0ERERB1Cgi4iIOIACXURExAEU6CIiIg6gQBcREXEABbqIiIgDKNBFREQcQIEuIiLiAAp0ERERB1Cgi4iIOIACXURExAEU6CIiIg6gQBcREXEABbqIiIgDKNBFREQcQIEuIiLiAAp0ERERB1Cgi4iIOIACXURExAEU6CIiIg6gQBcREXEABbqIiIgDKNBFREQcQIEuIiLiAAp0ERERB1Cgi4iIOIACXURExAEU6CIiIg6gQBcREXEABbqIiIgDDIhAN8bcYoz5zBiz2BjzvDEmM9E1iYiIDCYDItCB14Gp1tppwArgsgTXIyIiMqgMiEC31r5mrQ13fvgeUJDIekRERAabARHoWzkNeGVbB40xZxhjFhljFtXX1+/BskRERAYuz576QsaYN4D8Xg5dYa19ofM1VwBh4MltvY+1dj4wH2DWrFm2H0oVEREZdPZYoFtrj9jecWPMqcCxwOHWWgW1iIjIF7DHAn17jDFHA5cAX7bWtie6HhERkcFmoNxDvwvIAF43xnxkjLkv0QWJiIgMJgPiCt1aW5roGkRERAazgXKFLiIiIrtBgS4iIuIACnQREREHUKCLiIg4gAJdRETEARToIiIiDqBAFxERcQAFuoiIiAMo0EVERBxAgS4iIuIACnQREREHUKCLiIg4gAJdRETEARToIiIiDqBAFxERcQAFuoiIiAMo0EVERBxAgS4iIuIACnQREREHUKCLiIg4gAJdRETEARToIiIiDqBAFxERcQAFuoiIiAMo0EVERBxAgS4iIuIACnQREREHUKCLiIg4gAJdRETEARToIiIiDqBAFxERcQAFuoiIiAMo0EVERBxAgS4iIuIACnQREREHUKCLiIg4gAJdRETEARToIiIiDqBAFxERcQAFuoiIiAMo0EVERBxAgS4iIuIACnQREREHUKCLiIg4gAJdRETEARToIiIiDqBAFxERcQAFuoiIiAMo0EVERBxAgS4iIuIAAyrQjTEXGWOsMSYn0bWIiIgMJgMm0I0xY4EjgZpE1yIiIjLYDJhAB24DLgZsogsREREZbAZEoBtjjgNWW2s/3onXnmGMWWSMWVRfX78HqhMRERn4PHvqCxlj3gDyezl0BXA58JWdeR9r7XxgPsCsWbN0NS8iIsIeDHRr7RG9jRtj9gbGAx8bYwAKgA+NMXOstev2VH0iIiKD2R4L9G2x1i4B8rZ8bIypBmZZaxsSVpSIiMggMyDuoYuIiMjuSfgV+tastUWJrkFERGSw0RW6iIiIAyjQRUREHECBLiIi4gAKdBEREQdQoIuIiDiAAl1ERMQBFOgiIiIOoEAXERFxAAW6iIiIAyjQRUREHECBLiIi4gAKdBEREQdQoIuIiDiAAl1ERMQBFOgiIiIOoEAXERFxAAW6iIiIAyjQRUREHECBLiIi4gAKdBEREQdQoIuIiDiAAl1ERMQBFOgiIiIOoEAXERFxAGOtTXQNu8wY0wIsT3Qde0gO0JDoIvagoXS+Q+lcYWid71A6Vxha55uocx1nrc3t7YBnT1fSx5Zba2cluog9wRizaKicKwyt8x1K5wpD63yH0rnC0DrfgXiumnIXERFxAAW6iIiIAwz2QJ+f6AL2oKF0rjC0znconSsMrfMdSucKQ+t8B9y5DupFcSIiIhIz2K/QRUREBAW6iIiIIwzKQDfGHG2MWW6MqTDGXJroevqTMWasMeafxphlxphPjDHnJbqm/maMcRtj/meMeSnRtfQ3Y0ymMeYZY8xnnf+P9090Tf3FGHNB59/hpcaYPxhjkhNdU18yxjxsjNlgjFnabWyEMeZ1Y0x557+zElljX9rG+d7S+Xd5sTHmeWNMZiJr7Cu9nWu3YxcZY6wxJicRtXU36ALdGOMG7ga+CkwBvm+MmZLYqvpVGPi5tXYysB/wM4efL8B5wLJEF7GH3AG8aq2dBEzHoedtjBkDnAvMstZOBdzA9xJbVZ/7PXD0VmOXAv+w1pYB/+j82Cl+T8/zfR2Yaq2dBqwALtvTRfWT39PzXDHGjAWOBGr2dEG9GXSBDswBKqy1ldbaIPBH4PgE19RvrLVrrbUfdv65hdgP/DGJrar/GGMKgGOABxNdS38zxgwDDgYeArDWBq21TYmtql95gBRjjAdIBdYkuJ4+Za19G9i01fDxwKOdf34U+MYeLaof9Xa+1trXrLXhzg/fAwr2eGH9YBv/bwFuAy4GBsTq8sEY6GOA2m4f1+HggOvOGFME7Au8n9hK+tXtxL5BookuZA8oBuqBRzpvMTxojElLdFH9wVq7GvgtsSuZtcBma+1ria1qjxhprV0LsV/OgbwE17MnnQa8kugi+osx5jhgtbX240TXssVgDHTTy9iA+O2oPxlj0oFngfOttc2Jrqc/GGOOBTZYaz9IdC17iAeYAdxrrd0XaMNZU7JdOu8dHw+MB0YDacaYkxNblfQXY8wVxG4XPpnoWvqDMSYVuAL4ZaJr6W4wBnodMLbbxwU4bOpua8YYL7Ewf9Ja+1yi6+lHXwKOM8ZUE7uVcpgx5onEltSv6oA6a+2WGZdniAW8Ex0BVFlr6621IeA54IAE17QnrDfGjALo/PeGBNfT74wxpwLHAj+wzt3opITYL6cfd/68KgA+NMbkJ7KowRjoC4EyY8x4Y4yP2MKaFxNcU78xxhhi91iXWWt/l+h6+pO19jJrbYG1tojY/9c3rbWOvYqz1q4Dao0xEzuHDgc+TWBJ/akG2M8Yk9r5d/pwHLoAcCsvAqd2/vlU4IUE1tLvjDFHA5cAx1lr2xNdT3+x1i6x1uZZa4s6f17VATM6v6cTZtAFeueCi7OBvxP7gfC0tfaTxFbVr74EnELsavWjzn++luiipM+cAzxpjFkM7ANcn+B6+kXnLMQzwIfAEmI/ewbc1pm7wxjzB+BdYKIxps4Y8xPgRuBIY0w5sdXQNyayxr60jfO9C8gAXu/8WXVfQovsI9s41wFHW7+KiIg4wKC7QhcREZGeFOgiIiIOoEAXERFxAAW6iIiIAyjQRUREHECBLiIi4gAKdBEREQdQoIvIdhljfmqMuafbx9caYx5PZE0i0pM2lhGR7epsRLEc2Bs4EPgNcIC1tiOhhYlIHAW6iOyQMeZmIA34KnCktXZlgksSka0o0EVkh4wxk4j1TjjeWuvYZkgig5nuoYvIzvglUE+shzsAxphiY8xDxphnEleWiGyhQBeR7TLG/BxIBk4Eztsybq2ttNYOyK5TIkORZ8cvEZGhyhhzGPBjYH9rbYsxZpgxZh9r7UeJrk1E4ukKXUR6ZYwpBB4EvmOtbekcvgM4P3FVici2aFGciOwSY0w2cB1wJPCgtfaGBJckMqQp0EVERBxAU+4iIiIOoEAXERFxAAW6iIiIAyjQRUREHECBLiIi4gAKdBEREQdQoIuIiDiAAl1ERMQB/j+k7mabKBtn3gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "\n",
    "train = loadmat(r'D:\\DL\\HW2\\train.mat')\n",
    "test = loadmat(r'D:\\DL\\HW2\\test.mat')\n",
    "#print(train)\n",
    "x1_train,x2_train, y_train= train['x1'],train['x2'],train['y']\n",
    "#print(x1_train.shape,'\\n',x2_train.shape,'\\n',y_train.shape)\n",
    "x_train=np.hstack([x1_train,x2_train])\n",
    "\n",
    "x1_test,x2_test, y_test=test['x1'],test['x2'],test['y']\n",
    "x_test=np.hstack([x1_test,x2_test])\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import *\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train.ravel())\n",
    "y_pred = lr.predict(x_test)\n",
    "print('Coefficient:',lr.coef_)\n",
    "print('Interception:',lr.intercept_)\n",
    "print('misclassified',1-lr.score(x_test,y_test))\n",
    "\n",
    "xx, yy = np.mgrid[0:15:.01, -5:5:.01]\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "#probs = lr.predict_proba(grid)[:, 1].reshape(xx.shape)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.scatter(x1_train, x2_train, c=y_train, s=50,\n",
    "           cmap=\"RdBu\", vmin=-.2, vmax=1.2,\n",
    "           edgecolor=\"white\", linewidth=1)\n",
    "\n",
    "ax.set(aspect=\"equal\",\n",
    "       xlim=(0, 15), ylim=(-5, 5),\n",
    "       xlabel=\"$X_1$\", ylabel=\"$X_2$\")\n",
    "\n",
    "s = np.linspace(0.0, 10.0, num=70)\n",
    "line = -lr.coef_[0][0] / lr.coef_[0][1] * s - lr.intercept_ / lr.coef_[0][1] \n",
    "\n",
    "plt.plot(s,line,'-y',linewidth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.\n",
    "Please use a gradient descent method to solve Question 2. (show your code,decision boundary, and test error on the test dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a, b, c = 0.7314399999999928 -0.3922199999999978 -0.032399999999999804\n",
      "2 30\n",
      "misclassified: 0.06666666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15676d175f8>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data = loadmat(r'D:\\DL\\HW2\\train.mat')\n",
    "test = loadmat(r'D:\\DL\\HW2\\test.mat')\n",
    "\n",
    "x1,x2, y = data['x1'],data['x2'],data['y']\n",
    "xt1,xt2, yt = test['x1'],test['x2'],test['y']\n",
    "a = 1\n",
    "b = 0\n",
    "c = 0\n",
    "n = len(data['x1'])\n",
    "epoch = 1000\n",
    "lr = 0.0003\n",
    "for i in range(epoch):\n",
    "    y_pred = a * x2 + b*x1 + c\n",
    "    sign = np.sign(y - y_pred)\n",
    "    d_a = sum(-sign*x2)\n",
    "    d_b = sum(-sign*x1)\n",
    "    d_c = sum(-sign*1)\n",
    "    \n",
    "    a =a- lr * d_a\n",
    "    b =b- lr * d_b\n",
    "    c =c- lr * d_c\n",
    "\n",
    "\n",
    "print('a, b, c =',a[0],b[0],c[0]) #a=5.98 b=0.2\n",
    "y_pred = a*xt2 + b*xt1 + c \n",
    "\n",
    "miss_count=0\n",
    "for i in range(len(yt)):\n",
    "    if y_pred[i]>0:\n",
    "        y_pred[i]=1\n",
    "    else:\n",
    "        y_pred[i]=0\n",
    "        \n",
    "    if not y_pred[i] ==yt[i][0]:\n",
    "        miss_count+=1\n",
    "print(miss_count,len(yt))\n",
    "print('misclassified:',miss_count/len(yt))\n",
    "\n",
    "##Âúñ\n",
    "xx, yy = np.mgrid[0:15:.01, -5:5:.01]\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "ax.scatter(x1, x2, c=y, s=50,\n",
    "           cmap=\"RdBu\", vmin=-.2, vmax=1.2,\n",
    "           edgecolor=\"white\", linewidth=1)\n",
    "\n",
    "ax.set(aspect=\"equal\",\n",
    "       xlim=(0, 15), ylim=(-5, 5),\n",
    "       xlabel=\"$X_1$\", ylabel=\"$X_2$\")\n",
    "\n",
    "s = np.linspace(0.0, 10.0, num=70)\n",
    "line = -b / a * s - c / a\n",
    "plt.plot(s,line,'-y',linewidth=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.\n",
    " (15%, for bonus) Please use a neural network (with its architecture shown below)\n",
    "to find the decision boundary based on ‚Äòtrain.mat.‚Äù The activation function must be used\n",
    "in the two hidden layers and the output layer. You are required to use a gradient descent\n",
    "method to train the network. Report the test error on the test dataset ‚Äòtest.mat.‚Äô\n",
    "(percentage of misclassified test samples) Note that if you use any off-the-shelf functions\n",
    "to construct and optimize your network model, the most points you can get is 30% out of\n",
    "35%. If choosing to implement a neural network model by yourself (no built-in functions\n",
    "used), you will get the extra credit of at most 15%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "Cost:  [[0.77585691]]\n",
      "Accuracy: 50.0\n",
      "Iteration:  1\n",
      "Cost:  [[0.7268396]]\n",
      "Accuracy: 50.0\n",
      "Iteration:  2\n",
      "Cost:  [[0.70363802]]\n",
      "Accuracy: 50.0\n",
      "Iteration:  3\n",
      "Cost:  [[0.69397363]]\n",
      "Accuracy: 50.0\n",
      "Iteration:  4\n",
      "Cost:  [[0.69071597]]\n",
      "Accuracy: 50.0\n",
      "Iteration:  5\n",
      "Cost:  [[0.69020043]]\n",
      "Accuracy: 57.14285714285714\n",
      "Iteration:  6\n",
      "Cost:  [[0.69069824]]\n",
      "Accuracy: 57.14285714285714\n",
      "Iteration:  7\n",
      "Cost:  [[0.69145554]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  8\n",
      "Cost:  [[0.69217694]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  9\n",
      "Cost:  [[0.69276978]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  10\n",
      "Cost:  [[0.69322416]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  11\n",
      "Cost:  [[0.69355922]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  12\n",
      "Cost:  [[0.69380065]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  13\n",
      "Cost:  [[0.69397207]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  14\n",
      "Cost:  [[0.69409264]]\n",
      "Accuracy: 52.85714285714286\n",
      "Iteration:  15\n",
      "Cost:  [[0.69417691]]\n",
      "Accuracy: 52.85714285714286\n",
      "Iteration:  16\n",
      "Cost:  [[0.69423556]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  17\n",
      "Cost:  [[0.69427626]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  18\n",
      "Cost:  [[0.69430445]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  19\n",
      "Cost:  [[0.69432395]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  20\n",
      "Cost:  [[0.69433743]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  21\n",
      "Cost:  [[0.69434673]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  22\n",
      "Cost:  [[0.69435315]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  23\n",
      "Cost:  [[0.69435758]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  24\n",
      "Cost:  [[0.69436064]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  25\n",
      "Cost:  [[0.69436274]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  26\n",
      "Cost:  [[0.69436419]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  27\n",
      "Cost:  [[0.69436519]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  28\n",
      "Cost:  [[0.69436588]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  29\n",
      "Cost:  [[0.69436635]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  30\n",
      "Cost:  [[0.69436667]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  31\n",
      "Cost:  [[0.69436689]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  32\n",
      "Cost:  [[0.69436704]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  33\n",
      "Cost:  [[0.69436715]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  34\n",
      "Cost:  [[0.69436721]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  35\n",
      "Cost:  [[0.69436726]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  36\n",
      "Cost:  [[0.69436729]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  37\n",
      "Cost:  [[0.69436731]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  38\n",
      "Cost:  [[0.69436732]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  39\n",
      "Cost:  [[0.69436733]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  40\n",
      "Cost:  [[0.69436733]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  41\n",
      "Cost:  [[0.69436733]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  42\n",
      "Cost:  [[0.69436733]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  43\n",
      "Cost:  [[0.69436733]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  44\n",
      "Cost:  [[0.69436733]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  45\n",
      "Cost:  [[0.69436733]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  46\n",
      "Cost:  [[0.69436732]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  47\n",
      "Cost:  [[0.69436732]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  48\n",
      "Cost:  [[0.69436732]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  49\n",
      "Cost:  [[0.69436732]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  50\n",
      "Cost:  [[0.69436732]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  51\n",
      "Cost:  [[0.69436732]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  52\n",
      "Cost:  [[0.69436731]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  53\n",
      "Cost:  [[0.69436731]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  54\n",
      "Cost:  [[0.69436731]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  55\n",
      "Cost:  [[0.69436731]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  56\n",
      "Cost:  [[0.69436731]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  57\n",
      "Cost:  [[0.69436731]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  58\n",
      "Cost:  [[0.69436731]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  59\n",
      "Cost:  [[0.69436731]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  60\n",
      "Cost:  [[0.69436731]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  61\n",
      "Cost:  [[0.69436731]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  62\n",
      "Cost:  [[0.69436731]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  63\n",
      "Cost:  [[0.69436732]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  64\n",
      "Cost:  [[0.69436732]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  65\n",
      "Cost:  [[0.69436732]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  66\n",
      "Cost:  [[0.69436732]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  67\n",
      "Cost:  [[0.69436732]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  68\n",
      "Cost:  [[0.69436733]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  69\n",
      "Cost:  [[0.69436733]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  70\n",
      "Cost:  [[0.69436733]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  71\n",
      "Cost:  [[0.69436734]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  72\n",
      "Cost:  [[0.69436734]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  73\n",
      "Cost:  [[0.69436734]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  74\n",
      "Cost:  [[0.69436735]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  75\n",
      "Cost:  [[0.69436735]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  76\n",
      "Cost:  [[0.69436735]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  77\n",
      "Cost:  [[0.69436736]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  78\n",
      "Cost:  [[0.69436736]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  79\n",
      "Cost:  [[0.69436737]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  80\n",
      "Cost:  [[0.69436737]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  81\n",
      "Cost:  [[0.69436738]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  82\n",
      "Cost:  [[0.69436738]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  83\n",
      "Cost:  [[0.69436739]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  84\n",
      "Cost:  [[0.6943674]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  85\n",
      "Cost:  [[0.6943674]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  86\n",
      "Cost:  [[0.69436741]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  87\n",
      "Cost:  [[0.69436741]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  88\n",
      "Cost:  [[0.69436742]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  89\n",
      "Cost:  [[0.69436743]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  90\n",
      "Cost:  [[0.69436743]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  91\n",
      "Cost:  [[0.69436744]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  92\n",
      "Cost:  [[0.69436745]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  93\n",
      "Cost:  [[0.69436746]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  94\n",
      "Cost:  [[0.69436746]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  95\n",
      "Cost:  [[0.69436747]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  96\n",
      "Cost:  [[0.69436748]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  97\n",
      "Cost:  [[0.69436749]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  98\n",
      "Cost:  [[0.69436749]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  99\n",
      "Cost:  [[0.6943675]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  100\n",
      "Cost:  [[0.69436751]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  101\n",
      "Cost:  [[0.69436752]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  102\n",
      "Cost:  [[0.69436753]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  103\n",
      "Cost:  [[0.69436754]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  104\n",
      "Cost:  [[0.69436755]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  105\n",
      "Cost:  [[0.69436755]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  106\n",
      "Cost:  [[0.69436756]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  107\n",
      "Cost:  [[0.69436757]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  108\n",
      "Cost:  [[0.69436758]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  109\n",
      "Cost:  [[0.69436759]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  110\n",
      "Cost:  [[0.6943676]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  111\n",
      "Cost:  [[0.69436761]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  112\n",
      "Cost:  [[0.69436762]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  113\n",
      "Cost:  [[0.69436763]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  114\n",
      "Cost:  [[0.69436764]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  115\n",
      "Cost:  [[0.69436765]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  116\n",
      "Cost:  [[0.69436766]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  117\n",
      "Cost:  [[0.69436767]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  118\n",
      "Cost:  [[0.69436769]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  119\n",
      "Cost:  [[0.6943677]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  120\n",
      "Cost:  [[0.69436771]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  121\n",
      "Cost:  [[0.69436772]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  122\n",
      "Cost:  [[0.69436773]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  123\n",
      "Cost:  [[0.69436774]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  124\n",
      "Cost:  [[0.69436775]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  125\n",
      "Cost:  [[0.69436776]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  126\n",
      "Cost:  [[0.69436777]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  127\n",
      "Cost:  [[0.69436779]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  128\n",
      "Cost:  [[0.6943678]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  129\n",
      "Cost:  [[0.69436781]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  130\n",
      "Cost:  [[0.69436782]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  131\n",
      "Cost:  [[0.69436783]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  132\n",
      "Cost:  [[0.69436785]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  133\n",
      "Cost:  [[0.69436786]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  134\n",
      "Cost:  [[0.69436787]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  135\n",
      "Cost:  [[0.69436788]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  136\n",
      "Cost:  [[0.6943679]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  137\n",
      "Cost:  [[0.69436791]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  138\n",
      "Cost:  [[0.69436792]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  139\n",
      "Cost:  [[0.69436793]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  140\n",
      "Cost:  [[0.69436795]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  141\n",
      "Cost:  [[0.69436796]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  142\n",
      "Cost:  [[0.69436797]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  143\n",
      "Cost:  [[0.69436799]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  144\n",
      "Cost:  [[0.694368]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  145\n",
      "Cost:  [[0.69436801]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  146\n",
      "Cost:  [[0.69436803]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  147\n",
      "Cost:  [[0.69436804]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  148\n",
      "Cost:  [[0.69436805]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  149\n",
      "Cost:  [[0.69436807]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  150\n",
      "Cost:  [[0.69436808]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  151\n",
      "Cost:  [[0.69436809]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  152\n",
      "Cost:  [[0.69436811]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  153\n",
      "Cost:  [[0.69436812]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  154\n",
      "Cost:  [[0.69436813]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  155\n",
      "Cost:  [[0.69436815]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  156\n",
      "Cost:  [[0.69436816]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  157\n",
      "Cost:  [[0.69436817]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  158\n",
      "Cost:  [[0.69436819]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  159\n",
      "Cost:  [[0.6943682]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  160\n",
      "Cost:  [[0.69436822]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  161\n",
      "Cost:  [[0.69436823]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  162\n",
      "Cost:  [[0.69436824]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  163\n",
      "Cost:  [[0.69436826]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  164\n",
      "Cost:  [[0.69436827]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  165\n",
      "Cost:  [[0.69436829]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  166\n",
      "Cost:  [[0.6943683]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  167\n",
      "Cost:  [[0.69436832]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  168\n",
      "Cost:  [[0.69436833]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  169\n",
      "Cost:  [[0.69436834]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  170\n",
      "Cost:  [[0.69436836]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  171\n",
      "Cost:  [[0.69436837]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  172\n",
      "Cost:  [[0.69436839]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  173\n",
      "Cost:  [[0.6943684]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  174\n",
      "Cost:  [[0.69436842]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  175\n",
      "Cost:  [[0.69436843]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  176\n",
      "Cost:  [[0.69436844]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  177\n",
      "Cost:  [[0.69436846]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  178\n",
      "Cost:  [[0.69436847]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  179\n",
      "Cost:  [[0.69436849]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  180\n",
      "Cost:  [[0.6943685]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  181\n",
      "Cost:  [[0.69436852]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  182\n",
      "Cost:  [[0.69436853]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  183\n",
      "Cost:  [[0.69436855]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  184\n",
      "Cost:  [[0.69436856]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  185\n",
      "Cost:  [[0.69436858]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  186\n",
      "Cost:  [[0.69436859]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  187\n",
      "Cost:  [[0.69436861]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  188\n",
      "Cost:  [[0.69436862]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  189\n",
      "Cost:  [[0.69436863]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  190\n",
      "Cost:  [[0.69436865]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  191\n",
      "Cost:  [[0.69436866]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  192\n",
      "Cost:  [[0.69436868]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  193\n",
      "Cost:  [[0.69436869]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  194\n",
      "Cost:  [[0.69436871]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  195\n",
      "Cost:  [[0.69436872]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  196\n",
      "Cost:  [[0.69436874]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  197\n",
      "Cost:  [[0.69436875]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  198\n",
      "Cost:  [[0.69436877]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  199\n",
      "Cost:  [[0.69436878]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  200\n",
      "Cost:  [[0.69436879]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  201\n",
      "Cost:  [[0.69436881]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  202\n",
      "Cost:  [[0.69436882]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  203\n",
      "Cost:  [[0.69436884]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  204\n",
      "Cost:  [[0.69436885]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  205\n",
      "Cost:  [[0.69436887]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  206\n",
      "Cost:  [[0.69436888]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  207\n",
      "Cost:  [[0.6943689]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  208\n",
      "Cost:  [[0.69436891]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  209\n",
      "Cost:  [[0.69436892]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  210\n",
      "Cost:  [[0.69436894]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  211\n",
      "Cost:  [[0.69436895]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  212\n",
      "Cost:  [[0.69436897]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  213\n",
      "Cost:  [[0.69436898]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  214\n",
      "Cost:  [[0.694369]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  215\n",
      "Cost:  [[0.69436901]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  216\n",
      "Cost:  [[0.69436902]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  217\n",
      "Cost:  [[0.69436904]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  218\n",
      "Cost:  [[0.69436905]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  219\n",
      "Cost:  [[0.69436907]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  220\n",
      "Cost:  [[0.69436908]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  221\n",
      "Cost:  [[0.69436909]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  222\n",
      "Cost:  [[0.69436911]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  223\n",
      "Cost:  [[0.69436912]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  224\n",
      "Cost:  [[0.69436914]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  225\n",
      "Cost:  [[0.69436915]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  226\n",
      "Cost:  [[0.69436916]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  227\n",
      "Cost:  [[0.69436918]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  228\n",
      "Cost:  [[0.69436919]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  229\n",
      "Cost:  [[0.6943692]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  230\n",
      "Cost:  [[0.69436922]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  231\n",
      "Cost:  [[0.69436923]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  232\n",
      "Cost:  [[0.69436924]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  233\n",
      "Cost:  [[0.69436926]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  234\n",
      "Cost:  [[0.69436927]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  235\n",
      "Cost:  [[0.69436928]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  236\n",
      "Cost:  [[0.6943693]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  237\n",
      "Cost:  [[0.69436931]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  238\n",
      "Cost:  [[0.69436932]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  239\n",
      "Cost:  [[0.69436933]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  240\n",
      "Cost:  [[0.69436935]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  241\n",
      "Cost:  [[0.69436936]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  242\n",
      "Cost:  [[0.69436937]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  243\n",
      "Cost:  [[0.69436938]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  244\n",
      "Cost:  [[0.6943694]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  245\n",
      "Cost:  [[0.69436941]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  246\n",
      "Cost:  [[0.69436942]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  247\n",
      "Cost:  [[0.69436943]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  248\n",
      "Cost:  [[0.69436945]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  249\n",
      "Cost:  [[0.69436946]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  250\n",
      "Cost:  [[0.69436947]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  251\n",
      "Cost:  [[0.69436948]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  252\n",
      "Cost:  [[0.69436949]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  253\n",
      "Cost:  [[0.6943695]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  254\n",
      "Cost:  [[0.69436952]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  255\n",
      "Cost:  [[0.69436953]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  256\n",
      "Cost:  [[0.69436954]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  257\n",
      "Cost:  [[0.69436955]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  258\n",
      "Cost:  [[0.69436956]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  259\n",
      "Cost:  [[0.69436957]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  260\n",
      "Cost:  [[0.69436958]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  261\n",
      "Cost:  [[0.69436959]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  262\n",
      "Cost:  [[0.6943696]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  263\n",
      "Cost:  [[0.69436962]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  264\n",
      "Cost:  [[0.69436963]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  265\n",
      "Cost:  [[0.69436964]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  266\n",
      "Cost:  [[0.69436965]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  267\n",
      "Cost:  [[0.69436966]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  268\n",
      "Cost:  [[0.69436967]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  269\n",
      "Cost:  [[0.69436968]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  270\n",
      "Cost:  [[0.69436969]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  271\n",
      "Cost:  [[0.6943697]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  272\n",
      "Cost:  [[0.6943697]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  273\n",
      "Cost:  [[0.69436971]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  274\n",
      "Cost:  [[0.69436972]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  275\n",
      "Cost:  [[0.69436973]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  276\n",
      "Cost:  [[0.69436974]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  277\n",
      "Cost:  [[0.69436975]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  278\n",
      "Cost:  [[0.69436976]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  279\n",
      "Cost:  [[0.69436977]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  280\n",
      "Cost:  [[0.69436978]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  281\n",
      "Cost:  [[0.69436978]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  282\n",
      "Cost:  [[0.69436979]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  283\n",
      "Cost:  [[0.6943698]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  284\n",
      "Cost:  [[0.69436981]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  285\n",
      "Cost:  [[0.69436982]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  286\n",
      "Cost:  [[0.69436982]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  287\n",
      "Cost:  [[0.69436983]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  288\n",
      "Cost:  [[0.69436984]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  289\n",
      "Cost:  [[0.69436984]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  290\n",
      "Cost:  [[0.69436985]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  291\n",
      "Cost:  [[0.69436986]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  292\n",
      "Cost:  [[0.69436986]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  293\n",
      "Cost:  [[0.69436987]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  294\n",
      "Cost:  [[0.69436988]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  295\n",
      "Cost:  [[0.69436988]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  296\n",
      "Cost:  [[0.69436989]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  297\n",
      "Cost:  [[0.69436989]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  298\n",
      "Cost:  [[0.6943699]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  299\n",
      "Cost:  [[0.6943699]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  300\n",
      "Cost:  [[0.69436991]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  301\n",
      "Cost:  [[0.69436991]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  302\n",
      "Cost:  [[0.69436992]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  303\n",
      "Cost:  [[0.69436992]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  304\n",
      "Cost:  [[0.69436993]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  305\n",
      "Cost:  [[0.69436993]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  306\n",
      "Cost:  [[0.69436994]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  307\n",
      "Cost:  [[0.69436994]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  308\n",
      "Cost:  [[0.69436994]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  309\n",
      "Cost:  [[0.69436995]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  310\n",
      "Cost:  [[0.69436995]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  311\n",
      "Cost:  [[0.69436995]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  312\n",
      "Cost:  [[0.69436996]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  313\n",
      "Cost:  [[0.69436996]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  314\n",
      "Cost:  [[0.69436996]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  315\n",
      "Cost:  [[0.69436996]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  316\n",
      "Cost:  [[0.69436996]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  317\n",
      "Cost:  [[0.69436997]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  318\n",
      "Cost:  [[0.69436997]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  319\n",
      "Cost:  [[0.69436997]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  320\n",
      "Cost:  [[0.69436997]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  321\n",
      "Cost:  [[0.69436997]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  322\n",
      "Cost:  [[0.69436997]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  323\n",
      "Cost:  [[0.69436997]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  324\n",
      "Cost:  [[0.69436997]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  325\n",
      "Cost:  [[0.69436997]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  326\n",
      "Cost:  [[0.69436997]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  327\n",
      "Cost:  [[0.69436997]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  328\n",
      "Cost:  [[0.69436997]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  329\n",
      "Cost:  [[0.69436997]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  330\n",
      "Cost:  [[0.69436996]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  331\n",
      "Cost:  [[0.69436996]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  332\n",
      "Cost:  [[0.69436996]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  333\n",
      "Cost:  [[0.69436996]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  334\n",
      "Cost:  [[0.69436995]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  335\n",
      "Cost:  [[0.69436995]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  336\n",
      "Cost:  [[0.69436995]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  337\n",
      "Cost:  [[0.69436994]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  338\n",
      "Cost:  [[0.69436994]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  339\n",
      "Cost:  [[0.69436994]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  340\n",
      "Cost:  [[0.69436993]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  341\n",
      "Cost:  [[0.69436993]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  342\n",
      "Cost:  [[0.69436992]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  343\n",
      "Cost:  [[0.69436992]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  344\n",
      "Cost:  [[0.69436991]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  345\n",
      "Cost:  [[0.69436991]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  346\n",
      "Cost:  [[0.6943699]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  347\n",
      "Cost:  [[0.69436989]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  348\n",
      "Cost:  [[0.69436989]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  349\n",
      "Cost:  [[0.69436988]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  350\n",
      "Cost:  [[0.69436987]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  351\n",
      "Cost:  [[0.69436986]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  352\n",
      "Cost:  [[0.69436986]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  353\n",
      "Cost:  [[0.69436985]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  354\n",
      "Cost:  [[0.69436984]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  355\n",
      "Cost:  [[0.69436983]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  356\n",
      "Cost:  [[0.69436982]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  357\n",
      "Cost:  [[0.69436981]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  358\n",
      "Cost:  [[0.6943698]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  359\n",
      "Cost:  [[0.69436979]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  360\n",
      "Cost:  [[0.69436978]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  361\n",
      "Cost:  [[0.69436977]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  362\n",
      "Cost:  [[0.69436976]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  363\n",
      "Cost:  [[0.69436974]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  364\n",
      "Cost:  [[0.69436973]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  365\n",
      "Cost:  [[0.69436972]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  366\n",
      "Cost:  [[0.69436971]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  367\n",
      "Cost:  [[0.69436969]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  368\n",
      "Cost:  [[0.69436968]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  369\n",
      "Cost:  [[0.69436966]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  370\n",
      "Cost:  [[0.69436965]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  371\n",
      "Cost:  [[0.69436963]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  372\n",
      "Cost:  [[0.69436962]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  373\n",
      "Cost:  [[0.6943696]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  374\n",
      "Cost:  [[0.69436959]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  375\n",
      "Cost:  [[0.69436957]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  376\n",
      "Cost:  [[0.69436955]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  377\n",
      "Cost:  [[0.69436953]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  378\n",
      "Cost:  [[0.69436952]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  379\n",
      "Cost:  [[0.6943695]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  380\n",
      "Cost:  [[0.69436948]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  381\n",
      "Cost:  [[0.69436946]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  382\n",
      "Cost:  [[0.69436944]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  383\n",
      "Cost:  [[0.69436942]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  384\n",
      "Cost:  [[0.6943694]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  385\n",
      "Cost:  [[0.69436938]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  386\n",
      "Cost:  [[0.69436935]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  387\n",
      "Cost:  [[0.69436933]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  388\n",
      "Cost:  [[0.69436931]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  389\n",
      "Cost:  [[0.69436929]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  390\n",
      "Cost:  [[0.69436926]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  391\n",
      "Cost:  [[0.69436924]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  392\n",
      "Cost:  [[0.69436921]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  393\n",
      "Cost:  [[0.69436919]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  394\n",
      "Cost:  [[0.69436916]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  395\n",
      "Cost:  [[0.69436914]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  396\n",
      "Cost:  [[0.69436911]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  397\n",
      "Cost:  [[0.69436908]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  398\n",
      "Cost:  [[0.69436906]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  399\n",
      "Cost:  [[0.69436903]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  400\n",
      "Cost:  [[0.694369]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  401\n",
      "Cost:  [[0.69436897]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  402\n",
      "Cost:  [[0.69436894]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  403\n",
      "Cost:  [[0.69436891]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  404\n",
      "Cost:  [[0.69436888]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  405\n",
      "Cost:  [[0.69436885]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  406\n",
      "Cost:  [[0.69436881]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  407\n",
      "Cost:  [[0.69436878]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  408\n",
      "Cost:  [[0.69436875]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  409\n",
      "Cost:  [[0.69436871]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  410\n",
      "Cost:  [[0.69436868]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  411\n",
      "Cost:  [[0.69436864]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  412\n",
      "Cost:  [[0.69436861]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  413\n",
      "Cost:  [[0.69436857]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  414\n",
      "Cost:  [[0.69436853]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  415\n",
      "Cost:  [[0.6943685]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  416\n",
      "Cost:  [[0.69436846]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  417\n",
      "Cost:  [[0.69436842]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  418\n",
      "Cost:  [[0.69436838]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  419\n",
      "Cost:  [[0.69436834]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  420\n",
      "Cost:  [[0.6943683]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  421\n",
      "Cost:  [[0.69436826]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  422\n",
      "Cost:  [[0.69436821]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  423\n",
      "Cost:  [[0.69436817]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  424\n",
      "Cost:  [[0.69436813]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  425\n",
      "Cost:  [[0.69436808]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  426\n",
      "Cost:  [[0.69436804]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  427\n",
      "Cost:  [[0.69436799]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  428\n",
      "Cost:  [[0.69436794]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  429\n",
      "Cost:  [[0.6943679]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  430\n",
      "Cost:  [[0.69436785]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  431\n",
      "Cost:  [[0.6943678]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  432\n",
      "Cost:  [[0.69436775]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  433\n",
      "Cost:  [[0.6943677]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  434\n",
      "Cost:  [[0.69436765]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  435\n",
      "Cost:  [[0.6943676]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  436\n",
      "Cost:  [[0.69436754]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  437\n",
      "Cost:  [[0.69436749]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  438\n",
      "Cost:  [[0.69436744]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  439\n",
      "Cost:  [[0.69436738]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  440\n",
      "Cost:  [[0.69436732]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  441\n",
      "Cost:  [[0.69436727]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  442\n",
      "Cost:  [[0.69436721]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  443\n",
      "Cost:  [[0.69436715]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  444\n",
      "Cost:  [[0.69436709]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  445\n",
      "Cost:  [[0.69436703]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  446\n",
      "Cost:  [[0.69436697]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  447\n",
      "Cost:  [[0.69436691]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  448\n",
      "Cost:  [[0.69436685]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  449\n",
      "Cost:  [[0.69436678]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  450\n",
      "Cost:  [[0.69436672]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  451\n",
      "Cost:  [[0.69436665]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  452\n",
      "Cost:  [[0.69436658]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  453\n",
      "Cost:  [[0.69436652]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  454\n",
      "Cost:  [[0.69436645]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  455\n",
      "Cost:  [[0.69436638]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  456\n",
      "Cost:  [[0.69436631]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  457\n",
      "Cost:  [[0.69436624]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  458\n",
      "Cost:  [[0.69436616]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  459\n",
      "Cost:  [[0.69436609]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  460\n",
      "Cost:  [[0.69436602]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  461\n",
      "Cost:  [[0.69436594]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  462\n",
      "Cost:  [[0.69436586]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  463\n",
      "Cost:  [[0.69436579]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  464\n",
      "Cost:  [[0.69436571]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  465\n",
      "Cost:  [[0.69436563]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  466\n",
      "Cost:  [[0.69436555]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  467\n",
      "Cost:  [[0.69436546]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  468\n",
      "Cost:  [[0.69436538]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  469\n",
      "Cost:  [[0.6943653]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  470\n",
      "Cost:  [[0.69436521]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  471\n",
      "Cost:  [[0.69436513]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  472\n",
      "Cost:  [[0.69436504]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  473\n",
      "Cost:  [[0.69436495]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  474\n",
      "Cost:  [[0.69436486]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  475\n",
      "Cost:  [[0.69436477]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  476\n",
      "Cost:  [[0.69436468]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  477\n",
      "Cost:  [[0.69436458]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  478\n",
      "Cost:  [[0.69436449]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  479\n",
      "Cost:  [[0.69436439]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  480\n",
      "Cost:  [[0.69436429]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  481\n",
      "Cost:  [[0.69436419]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  482\n",
      "Cost:  [[0.69436409]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  483\n",
      "Cost:  [[0.69436399]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  484\n",
      "Cost:  [[0.69436389]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  485\n",
      "Cost:  [[0.69436379]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  486\n",
      "Cost:  [[0.69436368]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  487\n",
      "Cost:  [[0.69436358]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  488\n",
      "Cost:  [[0.69436347]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  489\n",
      "Cost:  [[0.69436336]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  490\n",
      "Cost:  [[0.69436325]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  491\n",
      "Cost:  [[0.69436313]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  492\n",
      "Cost:  [[0.69436302]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  493\n",
      "Cost:  [[0.69436291]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  494\n",
      "Cost:  [[0.69436279]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  495\n",
      "Cost:  [[0.69436267]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  496\n",
      "Cost:  [[0.69436255]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  497\n",
      "Cost:  [[0.69436243]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  498\n",
      "Cost:  [[0.69436231]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  499\n",
      "Cost:  [[0.69436218]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  500\n",
      "Cost:  [[0.69436206]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  501\n",
      "Cost:  [[0.69436193]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  502\n",
      "Cost:  [[0.6943618]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  503\n",
      "Cost:  [[0.69436167]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  504\n",
      "Cost:  [[0.69436154]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  505\n",
      "Cost:  [[0.69436141]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  506\n",
      "Cost:  [[0.69436127]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  507\n",
      "Cost:  [[0.69436113]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  508\n",
      "Cost:  [[0.69436099]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  509\n",
      "Cost:  [[0.69436085]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  510\n",
      "Cost:  [[0.69436071]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  511\n",
      "Cost:  [[0.69436057]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  512\n",
      "Cost:  [[0.69436042]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  513\n",
      "Cost:  [[0.69436027]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  514\n",
      "Cost:  [[0.69436012]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  515\n",
      "Cost:  [[0.69435997]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  516\n",
      "Cost:  [[0.69435982]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  517\n",
      "Cost:  [[0.69435966]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  518\n",
      "Cost:  [[0.69435951]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  519\n",
      "Cost:  [[0.69435935]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  520\n",
      "Cost:  [[0.69435918]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  521\n",
      "Cost:  [[0.69435902]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  522\n",
      "Cost:  [[0.69435886]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  523\n",
      "Cost:  [[0.69435869]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  524\n",
      "Cost:  [[0.69435852]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  525\n",
      "Cost:  [[0.69435835]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  526\n",
      "Cost:  [[0.69435818]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  527\n",
      "Cost:  [[0.694358]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  528\n",
      "Cost:  [[0.69435782]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  529\n",
      "Cost:  [[0.69435764]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  530\n",
      "Cost:  [[0.69435746]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  531\n",
      "Cost:  [[0.69435728]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  532\n",
      "Cost:  [[0.69435709]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  533\n",
      "Cost:  [[0.6943569]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  534\n",
      "Cost:  [[0.69435671]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  535\n",
      "Cost:  [[0.69435652]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  536\n",
      "Cost:  [[0.69435632]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  537\n",
      "Cost:  [[0.69435612]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  538\n",
      "Cost:  [[0.69435592]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  539\n",
      "Cost:  [[0.69435572]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  540\n",
      "Cost:  [[0.69435551]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  541\n",
      "Cost:  [[0.69435531]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  542\n",
      "Cost:  [[0.6943551]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  543\n",
      "Cost:  [[0.69435488]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  544\n",
      "Cost:  [[0.69435467]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  545\n",
      "Cost:  [[0.69435445]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  546\n",
      "Cost:  [[0.69435423]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  547\n",
      "Cost:  [[0.69435401]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  548\n",
      "Cost:  [[0.69435378]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  549\n",
      "Cost:  [[0.69435355]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  550\n",
      "Cost:  [[0.69435332]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  551\n",
      "Cost:  [[0.69435308]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  552\n",
      "Cost:  [[0.69435285]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  553\n",
      "Cost:  [[0.69435261]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  554\n",
      "Cost:  [[0.69435236]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  555\n",
      "Cost:  [[0.69435212]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  556\n",
      "Cost:  [[0.69435187]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  557\n",
      "Cost:  [[0.69435162]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  558\n",
      "Cost:  [[0.69435136]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  559\n",
      "Cost:  [[0.69435111]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  560\n",
      "Cost:  [[0.69435084]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  561\n",
      "Cost:  [[0.69435058]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  562\n",
      "Cost:  [[0.69435031]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  563\n",
      "Cost:  [[0.69435004]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  564\n",
      "Cost:  [[0.69434977]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  565\n",
      "Cost:  [[0.69434949]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  566\n",
      "Cost:  [[0.69434921]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  567\n",
      "Cost:  [[0.69434893]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  568\n",
      "Cost:  [[0.69434864]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  569\n",
      "Cost:  [[0.69434835]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  570\n",
      "Cost:  [[0.69434805]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  571\n",
      "Cost:  [[0.69434776]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  572\n",
      "Cost:  [[0.69434746]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  573\n",
      "Cost:  [[0.69434715]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  574\n",
      "Cost:  [[0.69434684]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  575\n",
      "Cost:  [[0.69434653]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  576\n",
      "Cost:  [[0.69434621]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  577\n",
      "Cost:  [[0.69434589]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  578\n",
      "Cost:  [[0.69434557]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  579\n",
      "Cost:  [[0.69434524]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  580\n",
      "Cost:  [[0.69434491]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  581\n",
      "Cost:  [[0.69434458]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  582\n",
      "Cost:  [[0.69434424]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  583\n",
      "Cost:  [[0.69434389]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  584\n",
      "Cost:  [[0.69434354]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  585\n",
      "Cost:  [[0.69434319]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  586\n",
      "Cost:  [[0.69434284]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  587\n",
      "Cost:  [[0.69434248]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  588\n",
      "Cost:  [[0.69434211]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  589\n",
      "Cost:  [[0.69434174]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  590\n",
      "Cost:  [[0.69434137]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  591\n",
      "Cost:  [[0.69434099]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  592\n",
      "Cost:  [[0.69434061]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  593\n",
      "Cost:  [[0.69434022]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  594\n",
      "Cost:  [[0.69433983]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  595\n",
      "Cost:  [[0.69433943]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  596\n",
      "Cost:  [[0.69433903]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  597\n",
      "Cost:  [[0.69433862]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  598\n",
      "Cost:  [[0.69433821]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  599\n",
      "Cost:  [[0.69433779]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  600\n",
      "Cost:  [[0.69433737]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  601\n",
      "Cost:  [[0.69433695]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  602\n",
      "Cost:  [[0.69433652]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  603\n",
      "Cost:  [[0.69433608]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  604\n",
      "Cost:  [[0.69433564]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  605\n",
      "Cost:  [[0.69433519]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  606\n",
      "Cost:  [[0.69433474]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  607\n",
      "Cost:  [[0.69433428]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  608\n",
      "Cost:  [[0.69433381]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  609\n",
      "Cost:  [[0.69433334]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  610\n",
      "Cost:  [[0.69433287]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  611\n",
      "Cost:  [[0.69433239]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  612\n",
      "Cost:  [[0.6943319]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  613\n",
      "Cost:  [[0.69433141]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  614\n",
      "Cost:  [[0.69433091]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  615\n",
      "Cost:  [[0.6943304]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  616\n",
      "Cost:  [[0.69432989]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  617\n",
      "Cost:  [[0.69432937]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  618\n",
      "Cost:  [[0.69432885]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  619\n",
      "Cost:  [[0.69432832]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  620\n",
      "Cost:  [[0.69432778]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  621\n",
      "Cost:  [[0.69432724]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  622\n",
      "Cost:  [[0.69432669]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  623\n",
      "Cost:  [[0.69432613]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  624\n",
      "Cost:  [[0.69432557]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  625\n",
      "Cost:  [[0.694325]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  626\n",
      "Cost:  [[0.69432442]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  627\n",
      "Cost:  [[0.69432384]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  628\n",
      "Cost:  [[0.69432325]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  629\n",
      "Cost:  [[0.69432265]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  630\n",
      "Cost:  [[0.69432204]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  631\n",
      "Cost:  [[0.69432143]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  632\n",
      "Cost:  [[0.69432081]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  633\n",
      "Cost:  [[0.69432018]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  634\n",
      "Cost:  [[0.69431954]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  635\n",
      "Cost:  [[0.6943189]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  636\n",
      "Cost:  [[0.69431824]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  637\n",
      "Cost:  [[0.69431758]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  638\n",
      "Cost:  [[0.69431691]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  639\n",
      "Cost:  [[0.69431624]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  640\n",
      "Cost:  [[0.69431555]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  641\n",
      "Cost:  [[0.69431486]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  642\n",
      "Cost:  [[0.69431415]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  643\n",
      "Cost:  [[0.69431344]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  644\n",
      "Cost:  [[0.69431272]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  645\n",
      "Cost:  [[0.69431199]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  646\n",
      "Cost:  [[0.69431125]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  647\n",
      "Cost:  [[0.69431051]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  648\n",
      "Cost:  [[0.69430975]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  649\n",
      "Cost:  [[0.69430898]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  650\n",
      "Cost:  [[0.69430821]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  651\n",
      "Cost:  [[0.69430742]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  652\n",
      "Cost:  [[0.69430662]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  653\n",
      "Cost:  [[0.69430582]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  654\n",
      "Cost:  [[0.694305]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  655\n",
      "Cost:  [[0.69430418]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  656\n",
      "Cost:  [[0.69430334]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  657\n",
      "Cost:  [[0.69430249]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  658\n",
      "Cost:  [[0.69430163]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  659\n",
      "Cost:  [[0.69430077]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  660\n",
      "Cost:  [[0.69429989]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  661\n",
      "Cost:  [[0.69429899]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  662\n",
      "Cost:  [[0.69429809]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  663\n",
      "Cost:  [[0.69429718]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  664\n",
      "Cost:  [[0.69429625]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  665\n",
      "Cost:  [[0.69429532]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  666\n",
      "Cost:  [[0.69429437]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  667\n",
      "Cost:  [[0.69429341]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  668\n",
      "Cost:  [[0.69429243]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  669\n",
      "Cost:  [[0.69429145]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  670\n",
      "Cost:  [[0.69429045]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  671\n",
      "Cost:  [[0.69428944]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  672\n",
      "Cost:  [[0.69428841]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  673\n",
      "Cost:  [[0.69428737]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  674\n",
      "Cost:  [[0.69428632]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  675\n",
      "Cost:  [[0.69428526]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  676\n",
      "Cost:  [[0.69428418]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  677\n",
      "Cost:  [[0.69428309]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  678\n",
      "Cost:  [[0.69428198]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  679\n",
      "Cost:  [[0.69428086]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  680\n",
      "Cost:  [[0.69427972]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  681\n",
      "Cost:  [[0.69427857]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  682\n",
      "Cost:  [[0.69427741]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  683\n",
      "Cost:  [[0.69427623]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  684\n",
      "Cost:  [[0.69427503]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  685\n",
      "Cost:  [[0.69427382]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  686\n",
      "Cost:  [[0.6942726]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  687\n",
      "Cost:  [[0.69427135]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  688\n",
      "Cost:  [[0.69427009]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  689\n",
      "Cost:  [[0.69426882]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  690\n",
      "Cost:  [[0.69426753]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  691\n",
      "Cost:  [[0.69426622]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  692\n",
      "Cost:  [[0.69426489]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  693\n",
      "Cost:  [[0.69426355]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  694\n",
      "Cost:  [[0.69426218]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  695\n",
      "Cost:  [[0.6942608]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  696\n",
      "Cost:  [[0.69425941]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  697\n",
      "Cost:  [[0.69425799]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  698\n",
      "Cost:  [[0.69425655]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  699\n",
      "Cost:  [[0.6942551]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  700\n",
      "Cost:  [[0.69425363]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  701\n",
      "Cost:  [[0.69425213]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  702\n",
      "Cost:  [[0.69425062]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  703\n",
      "Cost:  [[0.69424908]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  704\n",
      "Cost:  [[0.69424753]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  705\n",
      "Cost:  [[0.69424596]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  706\n",
      "Cost:  [[0.69424436]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  707\n",
      "Cost:  [[0.69424274]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  708\n",
      "Cost:  [[0.6942411]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  709\n",
      "Cost:  [[0.69423944]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  710\n",
      "Cost:  [[0.69423776]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  711\n",
      "Cost:  [[0.69423605]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  712\n",
      "Cost:  [[0.69423432]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  713\n",
      "Cost:  [[0.69423257]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  714\n",
      "Cost:  [[0.6942308]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  715\n",
      "Cost:  [[0.694229]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  716\n",
      "Cost:  [[0.69422717]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  717\n",
      "Cost:  [[0.69422532]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  718\n",
      "Cost:  [[0.69422345]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  719\n",
      "Cost:  [[0.69422155]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  720\n",
      "Cost:  [[0.69421962]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  721\n",
      "Cost:  [[0.69421767]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  722\n",
      "Cost:  [[0.69421569]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  723\n",
      "Cost:  [[0.69421368]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  724\n",
      "Cost:  [[0.69421165]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  725\n",
      "Cost:  [[0.69420959]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  726\n",
      "Cost:  [[0.6942075]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  727\n",
      "Cost:  [[0.69420538]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  728\n",
      "Cost:  [[0.69420323]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  729\n",
      "Cost:  [[0.69420106]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  730\n",
      "Cost:  [[0.69419885]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  731\n",
      "Cost:  [[0.69419661]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  732\n",
      "Cost:  [[0.69419434]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  733\n",
      "Cost:  [[0.69419204]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  734\n",
      "Cost:  [[0.69418971]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  735\n",
      "Cost:  [[0.69418734]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  736\n",
      "Cost:  [[0.69418494]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  737\n",
      "Cost:  [[0.69418251]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  738\n",
      "Cost:  [[0.69418005]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  739\n",
      "Cost:  [[0.69417755]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  740\n",
      "Cost:  [[0.69417501]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  741\n",
      "Cost:  [[0.69417244]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  742\n",
      "Cost:  [[0.69416984]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  743\n",
      "Cost:  [[0.69416719]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  744\n",
      "Cost:  [[0.69416451]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  745\n",
      "Cost:  [[0.6941618]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  746\n",
      "Cost:  [[0.69415904]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  747\n",
      "Cost:  [[0.69415625]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  748\n",
      "Cost:  [[0.69415341]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  749\n",
      "Cost:  [[0.69415054]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  750\n",
      "Cost:  [[0.69414762]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  751\n",
      "Cost:  [[0.69414467]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  752\n",
      "Cost:  [[0.69414167]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  753\n",
      "Cost:  [[0.69413863]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  754\n",
      "Cost:  [[0.69413554]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  755\n",
      "Cost:  [[0.69413241]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  756\n",
      "Cost:  [[0.69412924]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  757\n",
      "Cost:  [[0.69412602]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  758\n",
      "Cost:  [[0.69412276]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  759\n",
      "Cost:  [[0.69411945]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  760\n",
      "Cost:  [[0.69411609]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  761\n",
      "Cost:  [[0.69411268]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  762\n",
      "Cost:  [[0.69410923]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  763\n",
      "Cost:  [[0.69410572]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  764\n",
      "Cost:  [[0.69410216]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  765\n",
      "Cost:  [[0.69409856]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  766\n",
      "Cost:  [[0.6940949]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  767\n",
      "Cost:  [[0.69409119]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  768\n",
      "Cost:  [[0.69408742]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  769\n",
      "Cost:  [[0.6940836]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  770\n",
      "Cost:  [[0.69407972]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  771\n",
      "Cost:  [[0.69407579]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  772\n",
      "Cost:  [[0.6940718]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  773\n",
      "Cost:  [[0.69406776]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  774\n",
      "Cost:  [[0.69406365]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  775\n",
      "Cost:  [[0.69405949]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  776\n",
      "Cost:  [[0.69405526]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  777\n",
      "Cost:  [[0.69405097]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  778\n",
      "Cost:  [[0.69404662]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  779\n",
      "Cost:  [[0.69404221]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  780\n",
      "Cost:  [[0.69403773]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  781\n",
      "Cost:  [[0.69403318]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  782\n",
      "Cost:  [[0.69402857]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  783\n",
      "Cost:  [[0.69402389]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  784\n",
      "Cost:  [[0.69401914]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  785\n",
      "Cost:  [[0.69401433]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  786\n",
      "Cost:  [[0.69400944]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  787\n",
      "Cost:  [[0.69400448]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  788\n",
      "Cost:  [[0.69399944]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  789\n",
      "Cost:  [[0.69399433]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  790\n",
      "Cost:  [[0.69398915]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  791\n",
      "Cost:  [[0.69398389]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  792\n",
      "Cost:  [[0.69397855]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  793\n",
      "Cost:  [[0.69397313]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  794\n",
      "Cost:  [[0.69396763]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  795\n",
      "Cost:  [[0.69396205]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  796\n",
      "Cost:  [[0.69395639]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  797\n",
      "Cost:  [[0.69395064]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  798\n",
      "Cost:  [[0.6939448]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  799\n",
      "Cost:  [[0.69393888]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  800\n",
      "Cost:  [[0.69393287]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  801\n",
      "Cost:  [[0.69392677]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  802\n",
      "Cost:  [[0.69392058]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  803\n",
      "Cost:  [[0.6939143]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  804\n",
      "Cost:  [[0.69390792]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  805\n",
      "Cost:  [[0.69390144]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  806\n",
      "Cost:  [[0.69389487]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  807\n",
      "Cost:  [[0.6938882]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  808\n",
      "Cost:  [[0.69388143]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  809\n",
      "Cost:  [[0.69387455]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  810\n",
      "Cost:  [[0.69386758]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  811\n",
      "Cost:  [[0.69386049]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  812\n",
      "Cost:  [[0.6938533]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  813\n",
      "Cost:  [[0.693846]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  814\n",
      "Cost:  [[0.69383859]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  815\n",
      "Cost:  [[0.69383107]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  816\n",
      "Cost:  [[0.69382343]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  817\n",
      "Cost:  [[0.69381567]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  818\n",
      "Cost:  [[0.6938078]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  819\n",
      "Cost:  [[0.69379981]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  820\n",
      "Cost:  [[0.69379169]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  821\n",
      "Cost:  [[0.69378345]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  822\n",
      "Cost:  [[0.69377508]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  823\n",
      "Cost:  [[0.69376659]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  824\n",
      "Cost:  [[0.69375796]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  825\n",
      "Cost:  [[0.6937492]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  826\n",
      "Cost:  [[0.6937403]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  827\n",
      "Cost:  [[0.69373127]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  828\n",
      "Cost:  [[0.6937221]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  829\n",
      "Cost:  [[0.69371278]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  830\n",
      "Cost:  [[0.69370332]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  831\n",
      "Cost:  [[0.69369371]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  832\n",
      "Cost:  [[0.69368396]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  833\n",
      "Cost:  [[0.69367404]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  834\n",
      "Cost:  [[0.69366398]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  835\n",
      "Cost:  [[0.69365375]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  836\n",
      "Cost:  [[0.69364337]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  837\n",
      "Cost:  [[0.69363282]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  838\n",
      "Cost:  [[0.69362211]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  839\n",
      "Cost:  [[0.69361122]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  840\n",
      "Cost:  [[0.69360016]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  841\n",
      "Cost:  [[0.69358893]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  842\n",
      "Cost:  [[0.69357752]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  843\n",
      "Cost:  [[0.69356593]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  844\n",
      "Cost:  [[0.69355415]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  845\n",
      "Cost:  [[0.69354218]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  846\n",
      "Cost:  [[0.69353002]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  847\n",
      "Cost:  [[0.69351766]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  848\n",
      "Cost:  [[0.6935051]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  849\n",
      "Cost:  [[0.69349234]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  850\n",
      "Cost:  [[0.69347937]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  851\n",
      "Cost:  [[0.69346619]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  852\n",
      "Cost:  [[0.69345279]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  853\n",
      "Cost:  [[0.69343918]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  854\n",
      "Cost:  [[0.69342534]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  855\n",
      "Cost:  [[0.69341127]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  856\n",
      "Cost:  [[0.69339697]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  857\n",
      "Cost:  [[0.69338243]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  858\n",
      "Cost:  [[0.69336765]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  859\n",
      "Cost:  [[0.69335262]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  860\n",
      "Cost:  [[0.69333734]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  861\n",
      "Cost:  [[0.6933218]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  862\n",
      "Cost:  [[0.693306]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  863\n",
      "Cost:  [[0.69328993]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  864\n",
      "Cost:  [[0.69327359]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  865\n",
      "Cost:  [[0.69325697]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  866\n",
      "Cost:  [[0.69324007]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  867\n",
      "Cost:  [[0.69322287]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  868\n",
      "Cost:  [[0.69320537]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  869\n",
      "Cost:  [[0.69318757]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  870\n",
      "Cost:  [[0.69316947]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  871\n",
      "Cost:  [[0.69315104]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  872\n",
      "Cost:  [[0.69313229]]\n",
      "Accuracy: 54.285714285714285\n",
      "Iteration:  873\n",
      "Cost:  [[0.69311321]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  874\n",
      "Cost:  [[0.69309379]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  875\n",
      "Cost:  [[0.69307402]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  876\n",
      "Cost:  [[0.69305391]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  877\n",
      "Cost:  [[0.69303342]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  878\n",
      "Cost:  [[0.69301257]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  879\n",
      "Cost:  [[0.69299134]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  880\n",
      "Cost:  [[0.69296973]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  881\n",
      "Cost:  [[0.69294771]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  882\n",
      "Cost:  [[0.6929253]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  883\n",
      "Cost:  [[0.69290246]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  884\n",
      "Cost:  [[0.6928792]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  885\n",
      "Cost:  [[0.69285551]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  886\n",
      "Cost:  [[0.69283137]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  887\n",
      "Cost:  [[0.69280678]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  888\n",
      "Cost:  [[0.69278171]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  889\n",
      "Cost:  [[0.69275617]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  890\n",
      "Cost:  [[0.69273014]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  891\n",
      "Cost:  [[0.69270361]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  892\n",
      "Cost:  [[0.69267656]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  893\n",
      "Cost:  [[0.69264898]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  894\n",
      "Cost:  [[0.69262086]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  895\n",
      "Cost:  [[0.69259219]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  896\n",
      "Cost:  [[0.69256294]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  897\n",
      "Cost:  [[0.69253312]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  898\n",
      "Cost:  [[0.69250269]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  899\n",
      "Cost:  [[0.69247165]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  900\n",
      "Cost:  [[0.69243998]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  901\n",
      "Cost:  [[0.69240766]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  902\n",
      "Cost:  [[0.69237468]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  903\n",
      "Cost:  [[0.69234101]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  904\n",
      "Cost:  [[0.69230664]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  905\n",
      "Cost:  [[0.69227156]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  906\n",
      "Cost:  [[0.69223573]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  907\n",
      "Cost:  [[0.69219915]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  908\n",
      "Cost:  [[0.69216178]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  909\n",
      "Cost:  [[0.69212362]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  910\n",
      "Cost:  [[0.69208463]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  911\n",
      "Cost:  [[0.69204479]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  912\n",
      "Cost:  [[0.69200408]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  913\n",
      "Cost:  [[0.69196248]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  914\n",
      "Cost:  [[0.69191996]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  915\n",
      "Cost:  [[0.69187649]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  916\n",
      "Cost:  [[0.69183204]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  917\n",
      "Cost:  [[0.6917866]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  918\n",
      "Cost:  [[0.69174012]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  919\n",
      "Cost:  [[0.69169257]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  920\n",
      "Cost:  [[0.69164394]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  921\n",
      "Cost:  [[0.69159418]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  922\n",
      "Cost:  [[0.69154326]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  923\n",
      "Cost:  [[0.69149114]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  924\n",
      "Cost:  [[0.6914378]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  925\n",
      "Cost:  [[0.69138319]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  926\n",
      "Cost:  [[0.69132727]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  927\n",
      "Cost:  [[0.69127001]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  928\n",
      "Cost:  [[0.69121136]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  929\n",
      "Cost:  [[0.69115128]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  930\n",
      "Cost:  [[0.69108972]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  931\n",
      "Cost:  [[0.69102664]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  932\n",
      "Cost:  [[0.69096199]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  933\n",
      "Cost:  [[0.69089572]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  934\n",
      "Cost:  [[0.69082778]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  935\n",
      "Cost:  [[0.69075811]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  936\n",
      "Cost:  [[0.69068667]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  937\n",
      "Cost:  [[0.69061338]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  938\n",
      "Cost:  [[0.69053819]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  939\n",
      "Cost:  [[0.69046104]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  940\n",
      "Cost:  [[0.69038186]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  941\n",
      "Cost:  [[0.69030058]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  942\n",
      "Cost:  [[0.69021714]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  943\n",
      "Cost:  [[0.69013146]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  944\n",
      "Cost:  [[0.69004346]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  945\n",
      "Cost:  [[0.68995306]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  946\n",
      "Cost:  [[0.68986019]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  947\n",
      "Cost:  [[0.68976475]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  948\n",
      "Cost:  [[0.68966665]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  949\n",
      "Cost:  [[0.68956581]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  950\n",
      "Cost:  [[0.68946211]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  951\n",
      "Cost:  [[0.68935547]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  952\n",
      "Cost:  [[0.68924578]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  953\n",
      "Cost:  [[0.68913291]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  954\n",
      "Cost:  [[0.68901677]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  955\n",
      "Cost:  [[0.68889722]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  956\n",
      "Cost:  [[0.68877415]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  957\n",
      "Cost:  [[0.68864741]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  958\n",
      "Cost:  [[0.68851688]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  959\n",
      "Cost:  [[0.6883824]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  960\n",
      "Cost:  [[0.68824383]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  961\n",
      "Cost:  [[0.68810101]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  962\n",
      "Cost:  [[0.68795377]]\n",
      "Accuracy: 55.714285714285715\n",
      "Iteration:  963\n",
      "Cost:  [[0.68780195]]\n",
      "Accuracy: 57.14285714285714\n",
      "Iteration:  964\n",
      "Cost:  [[0.68764535]]\n",
      "Accuracy: 57.14285714285714\n",
      "Iteration:  965\n",
      "Cost:  [[0.6874838]]\n",
      "Accuracy: 58.57142857142858\n",
      "Iteration:  966\n",
      "Cost:  [[0.6873171]]\n",
      "Accuracy: 58.57142857142858\n",
      "Iteration:  967\n",
      "Cost:  [[0.68714504]]\n",
      "Accuracy: 60.0\n",
      "Iteration:  968\n",
      "Cost:  [[0.68696739]]\n",
      "Accuracy: 60.0\n",
      "Iteration:  969\n",
      "Cost:  [[0.68678394]]\n",
      "Accuracy: 60.0\n",
      "Iteration:  970\n",
      "Cost:  [[0.68659444]]\n",
      "Accuracy: 60.0\n",
      "Iteration:  971\n",
      "Cost:  [[0.68639865]]\n",
      "Accuracy: 60.0\n",
      "Iteration:  972\n",
      "Cost:  [[0.6861963]]\n",
      "Accuracy: 60.0\n",
      "Iteration:  973\n",
      "Cost:  [[0.68598711]]\n",
      "Accuracy: 60.0\n",
      "Iteration:  974\n",
      "Cost:  [[0.6857708]]\n",
      "Accuracy: 60.0\n",
      "Iteration:  975\n",
      "Cost:  [[0.68554707]]\n",
      "Accuracy: 60.0\n",
      "Iteration:  976\n",
      "Cost:  [[0.68531559]]\n",
      "Accuracy: 61.42857142857143\n",
      "Iteration:  977\n",
      "Cost:  [[0.68507602]]\n",
      "Accuracy: 61.42857142857143\n",
      "Iteration:  978\n",
      "Cost:  [[0.68482803]]\n",
      "Accuracy: 61.42857142857143\n",
      "Iteration:  979\n",
      "Cost:  [[0.68457123]]\n",
      "Accuracy: 61.42857142857143\n",
      "Iteration:  980\n",
      "Cost:  [[0.68430524]]\n",
      "Accuracy: 61.42857142857143\n",
      "Iteration:  981\n",
      "Cost:  [[0.68402965]]\n",
      "Accuracy: 61.42857142857143\n",
      "Iteration:  982\n",
      "Cost:  [[0.68374403]]\n",
      "Accuracy: 61.42857142857143\n",
      "Iteration:  983\n",
      "Cost:  [[0.68344793]]\n",
      "Accuracy: 61.42857142857143\n",
      "Iteration:  984\n",
      "Cost:  [[0.68314088]]\n",
      "Accuracy: 61.42857142857143\n",
      "Iteration:  985\n",
      "Cost:  [[0.68282236]]\n",
      "Accuracy: 61.42857142857143\n",
      "Iteration:  986\n",
      "Cost:  [[0.68249187]]\n",
      "Accuracy: 61.42857142857143\n",
      "Iteration:  987\n",
      "Cost:  [[0.68214884]]\n",
      "Accuracy: 61.42857142857143\n",
      "Iteration:  988\n",
      "Cost:  [[0.68179268]]\n",
      "Accuracy: 61.42857142857143\n",
      "Iteration:  989\n",
      "Cost:  [[0.6814228]]\n",
      "Accuracy: 61.42857142857143\n",
      "Iteration:  990\n",
      "Cost:  [[0.68103854]]\n",
      "Accuracy: 61.42857142857143\n",
      "Iteration:  991\n",
      "Cost:  [[0.68063922]]\n",
      "Accuracy: 61.42857142857143\n",
      "Iteration:  992\n",
      "Cost:  [[0.68022413]]\n",
      "Accuracy: 61.42857142857143\n",
      "Iteration:  993\n",
      "Cost:  [[0.67979252]]\n",
      "Accuracy: 61.42857142857143\n",
      "Iteration:  994\n",
      "Cost:  [[0.67934359]]\n",
      "Accuracy: 61.42857142857143\n",
      "Iteration:  995\n",
      "Cost:  [[0.6788765]]\n",
      "Accuracy: 61.42857142857143\n",
      "Iteration:  996\n",
      "Cost:  [[0.67839038]]\n",
      "Accuracy: 61.42857142857143\n",
      "Iteration:  997\n",
      "Cost:  [[0.67788431]]\n",
      "Accuracy: 61.42857142857143\n",
      "Iteration:  998\n",
      "Cost:  [[0.67735731]]\n",
      "Accuracy: 61.42857142857143\n",
      "Iteration:  999\n",
      "Cost:  [[0.67680835]]\n",
      "Accuracy: 62.857142857142854\n",
      "Iteration:  1000\n",
      "Cost:  [[0.67623635]]\n",
      "Accuracy: 62.857142857142854\n",
      "Iteration:  1001\n",
      "Cost:  [[0.67564019]]\n",
      "Accuracy: 64.28571428571429\n",
      "Iteration:  1002\n",
      "Cost:  [[0.67501866]]\n",
      "Accuracy: 67.14285714285714\n",
      "Iteration:  1003\n",
      "Cost:  [[0.67437051]]\n",
      "Accuracy: 67.14285714285714\n",
      "Iteration:  1004\n",
      "Cost:  [[0.67369441]]\n",
      "Accuracy: 67.14285714285714\n",
      "Iteration:  1005\n",
      "Cost:  [[0.67298899]]\n",
      "Accuracy: 67.14285714285714\n",
      "Iteration:  1006\n",
      "Cost:  [[0.67225277]]\n",
      "Accuracy: 67.14285714285714\n",
      "Iteration:  1007\n",
      "Cost:  [[0.67148422]]\n",
      "Accuracy: 67.14285714285714\n",
      "Iteration:  1008\n",
      "Cost:  [[0.67068174]]\n",
      "Accuracy: 67.14285714285714\n",
      "Iteration:  1009\n",
      "Cost:  [[0.66984363]]\n",
      "Accuracy: 67.14285714285714\n",
      "Iteration:  1010\n",
      "Cost:  [[0.66896811]]\n",
      "Accuracy: 67.14285714285714\n",
      "Iteration:  1011\n",
      "Cost:  [[0.66805332]]\n",
      "Accuracy: 67.14285714285714\n",
      "Iteration:  1012\n",
      "Cost:  [[0.66709732]]\n",
      "Accuracy: 68.57142857142857\n",
      "Iteration:  1013\n",
      "Cost:  [[0.66609805]]\n",
      "Accuracy: 68.57142857142857\n",
      "Iteration:  1014\n",
      "Cost:  [[0.66505338]]\n",
      "Accuracy: 68.57142857142857\n",
      "Iteration:  1015\n",
      "Cost:  [[0.66396107]]\n",
      "Accuracy: 70.0\n",
      "Iteration:  1016\n",
      "Cost:  [[0.66281878]]\n",
      "Accuracy: 70.0\n",
      "Iteration:  1017\n",
      "Cost:  [[0.66162406]]\n",
      "Accuracy: 71.42857142857143\n",
      "Iteration:  1018\n",
      "Cost:  [[0.66037438]]\n",
      "Accuracy: 71.42857142857143\n",
      "Iteration:  1019\n",
      "Cost:  [[0.65906707]]\n",
      "Accuracy: 71.42857142857143\n",
      "Iteration:  1020\n",
      "Cost:  [[0.65769937]]\n",
      "Accuracy: 71.42857142857143\n",
      "Iteration:  1021\n",
      "Cost:  [[0.65626841]]\n",
      "Accuracy: 72.85714285714285\n",
      "Iteration:  1022\n",
      "Cost:  [[0.65477122]]\n",
      "Accuracy: 72.85714285714285\n",
      "Iteration:  1023\n",
      "Cost:  [[0.65320469]]\n",
      "Accuracy: 72.85714285714285\n",
      "Iteration:  1024\n",
      "Cost:  [[0.65156563]]\n",
      "Accuracy: 72.85714285714285\n",
      "Iteration:  1025\n",
      "Cost:  [[0.64985074]]\n",
      "Accuracy: 72.85714285714285\n",
      "Iteration:  1026\n",
      "Cost:  [[0.64805662]]\n",
      "Accuracy: 74.28571428571429\n",
      "Iteration:  1027\n",
      "Cost:  [[0.64617976]]\n",
      "Accuracy: 74.28571428571429\n",
      "Iteration:  1028\n",
      "Cost:  [[0.64421656]]\n",
      "Accuracy: 75.71428571428571\n",
      "Iteration:  1029\n",
      "Cost:  [[0.64216334]]\n",
      "Accuracy: 77.14285714285715\n",
      "Iteration:  1030\n",
      "Cost:  [[0.64001634]]\n",
      "Accuracy: 77.14285714285715\n",
      "Iteration:  1031\n",
      "Cost:  [[0.63777174]]\n",
      "Accuracy: 80.0\n",
      "Iteration:  1032\n",
      "Cost:  [[0.63542563]]\n",
      "Accuracy: 80.0\n",
      "Iteration:  1033\n",
      "Cost:  [[0.63297409]]\n",
      "Accuracy: 80.0\n",
      "Iteration:  1034\n",
      "Cost:  [[0.63041316]]\n",
      "Accuracy: 84.28571428571429\n",
      "Iteration:  1035\n",
      "Cost:  [[0.62773885]]\n",
      "Accuracy: 84.28571428571429\n",
      "Iteration:  1036\n",
      "Cost:  [[0.62494721]]\n",
      "Accuracy: 84.28571428571429\n",
      "Iteration:  1037\n",
      "Cost:  [[0.62203427]]\n",
      "Accuracy: 85.71428571428571\n",
      "Iteration:  1038\n",
      "Cost:  [[0.61899616]]\n",
      "Accuracy: 88.57142857142857\n",
      "Iteration:  1039\n",
      "Cost:  [[0.61582904]]\n",
      "Accuracy: 90.0\n",
      "Iteration:  1040\n",
      "Cost:  [[0.61252921]]\n",
      "Accuracy: 91.42857142857143\n",
      "Iteration:  1041\n",
      "Cost:  [[0.60909306]]\n",
      "Accuracy: 91.42857142857143\n",
      "Iteration:  1042\n",
      "Cost:  [[0.60551719]]\n",
      "Accuracy: 91.42857142857143\n",
      "Iteration:  1043\n",
      "Cost:  [[0.60179837]]\n",
      "Accuracy: 91.42857142857143\n",
      "Iteration:  1044\n",
      "Cost:  [[0.59793359]]\n",
      "Accuracy: 92.85714285714286\n",
      "Iteration:  1045\n",
      "Cost:  [[0.59392013]]\n",
      "Accuracy: 92.85714285714286\n",
      "Iteration:  1046\n",
      "Cost:  [[0.58975557]]\n",
      "Accuracy: 94.28571428571428\n",
      "Iteration:  1047\n",
      "Cost:  [[0.58543783]]\n",
      "Accuracy: 94.28571428571428\n",
      "Iteration:  1048\n",
      "Cost:  [[0.58096522]]\n",
      "Accuracy: 94.28571428571428\n",
      "Iteration:  1049\n",
      "Cost:  [[0.57633646]]\n",
      "Accuracy: 94.28571428571428\n",
      "Iteration:  1050\n",
      "Cost:  [[0.57155074]]\n",
      "Accuracy: 95.71428571428572\n",
      "Iteration:  1051\n",
      "Cost:  [[0.56660773]]\n",
      "Accuracy: 95.71428571428572\n",
      "Iteration:  1052\n",
      "Cost:  [[0.56150765]]\n",
      "Accuracy: 97.14285714285714\n",
      "Iteration:  1053\n",
      "Cost:  [[0.55625127]]\n",
      "Accuracy: 97.14285714285714\n",
      "Iteration:  1054\n",
      "Cost:  [[0.55083995]]\n",
      "Accuracy: 97.14285714285714\n",
      "Iteration:  1055\n",
      "Cost:  [[0.54527568]]\n",
      "Accuracy: 97.14285714285714\n",
      "Iteration:  1056\n",
      "Cost:  [[0.53956107]]\n",
      "Accuracy: 97.14285714285714\n",
      "Iteration:  1057\n",
      "Cost:  [[0.53369939]]\n",
      "Accuracy: 97.14285714285714\n",
      "Iteration:  1058\n",
      "Cost:  [[0.52769457]]\n",
      "Accuracy: 97.14285714285714\n",
      "Iteration:  1059\n",
      "Cost:  [[0.52155121]]\n",
      "Accuracy: 97.14285714285714\n",
      "Iteration:  1060\n",
      "Cost:  [[0.51527457]]\n",
      "Accuracy: 98.57142857142858\n",
      "Iteration:  1061\n",
      "Cost:  [[0.50887053]]\n",
      "Accuracy: 98.57142857142858\n",
      "Iteration:  1062\n",
      "Cost:  [[0.50234564]]\n",
      "Accuracy: 98.57142857142858\n",
      "Iteration:  1063\n",
      "Cost:  [[0.49570703]]\n",
      "Accuracy: 98.57142857142858\n",
      "Iteration:  1064\n",
      "Cost:  [[0.48896239]]\n",
      "Accuracy: 98.57142857142858\n",
      "Iteration:  1065\n",
      "Cost:  [[0.48211998]]\n",
      "Accuracy: 98.57142857142858\n",
      "Iteration:  1066\n",
      "Cost:  [[0.4751885]]\n",
      "Accuracy: 98.57142857142858\n",
      "Iteration:  1067\n",
      "Cost:  [[0.46817709]]\n",
      "Accuracy: 98.57142857142858\n",
      "Iteration:  1068\n",
      "Cost:  [[0.46109526]]\n",
      "Accuracy: 98.57142857142858\n",
      "Iteration:  1069\n",
      "Cost:  [[0.45395285]]\n",
      "Accuracy: 98.57142857142858\n",
      "Iteration:  1070\n",
      "Cost:  [[0.44675991]]\n",
      "Accuracy: 98.57142857142858\n",
      "Iteration:  1071\n",
      "Cost:  [[0.43952666]]\n",
      "Accuracy: 98.57142857142858\n",
      "Iteration:  1072\n",
      "Cost:  [[0.43226346]]\n",
      "Accuracy: 98.57142857142858\n",
      "Iteration:  1073\n",
      "Cost:  [[0.42498065]]\n",
      "Accuracy: 98.57142857142858\n",
      "Iteration:  1074\n",
      "Cost:  [[0.41768856]]\n",
      "Accuracy: 98.57142857142858\n",
      "Iteration:  1075\n",
      "Cost:  [[0.41039742]]\n",
      "Accuracy: 98.57142857142858\n",
      "Iteration:  1076\n",
      "Cost:  [[0.40311726]]\n",
      "Accuracy: 98.57142857142858\n",
      "Iteration:  1077\n",
      "Cost:  [[0.39585788]]\n",
      "Accuracy: 98.57142857142858\n",
      "Iteration:  1078\n",
      "Cost:  [[0.38862881]]\n",
      "Accuracy: 98.57142857142858\n",
      "Iteration:  1079\n",
      "Cost:  [[0.3814392]]\n",
      "Accuracy: 98.57142857142858\n",
      "Iteration:  1080\n",
      "Cost:  [[0.37429784]]\n",
      "Accuracy: 98.57142857142858\n",
      "Iteration:  1081\n",
      "Cost:  [[0.36721306]]\n",
      "Accuracy: 98.57142857142858\n",
      "Iteration:  1082\n",
      "Cost:  [[0.36019273]]\n",
      "Accuracy: 98.57142857142858\n",
      "Iteration:  1083\n",
      "Cost:  [[0.35324422]]\n",
      "Accuracy: 98.57142857142858\n",
      "Iteration:  1084\n",
      "Cost:  [[0.34637439]]\n",
      "Accuracy: 98.57142857142858\n",
      "Iteration:  1085\n",
      "Cost:  [[0.33958955]]\n",
      "Accuracy: 98.57142857142858\n",
      "Iteration:  1086\n",
      "Cost:  [[0.33289546]]\n",
      "Accuracy: 98.57142857142858\n",
      "Iteration:  1087\n",
      "Cost:  [[0.32629736]]\n",
      "Accuracy: 98.57142857142858\n",
      "Iteration:  1088\n",
      "Cost:  [[0.3197999]]\n",
      "Accuracy: 98.57142857142858\n",
      "Iteration:  1089\n",
      "Cost:  [[0.31340722]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1090\n",
      "Cost:  [[0.30712292]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1091\n",
      "Cost:  [[0.30095006]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1092\n",
      "Cost:  [[0.29489125]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1093\n",
      "Cost:  [[0.28894857]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1094\n",
      "Cost:  [[0.28312368]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1095\n",
      "Cost:  [[0.27741781]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1096\n",
      "Cost:  [[0.27183176]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1097\n",
      "Cost:  [[0.266366]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1098\n",
      "Cost:  [[0.2610206]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1099\n",
      "Cost:  [[0.25579535]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1100\n",
      "Cost:  [[0.25068974]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1101\n",
      "Cost:  [[0.24570298]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1102\n",
      "Cost:  [[0.24083406]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1103\n",
      "Cost:  [[0.23608175]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1104\n",
      "Cost:  [[0.23144462]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1105\n",
      "Cost:  [[0.22692109]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1106\n",
      "Cost:  [[0.22250941]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1107\n",
      "Cost:  [[0.21820775]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1108\n",
      "Cost:  [[0.21401412]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1109\n",
      "Cost:  [[0.20992648]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1110\n",
      "Cost:  [[0.2059427]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1111\n",
      "Cost:  [[0.2020606]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1112\n",
      "Cost:  [[0.19827795]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1113\n",
      "Cost:  [[0.19459249]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1114\n",
      "Cost:  [[0.19100195]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1115\n",
      "Cost:  [[0.18750401]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1116\n",
      "Cost:  [[0.1840964]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1117\n",
      "Cost:  [[0.18077683]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1118\n",
      "Cost:  [[0.177543]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1119\n",
      "Cost:  [[0.17439268]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1120\n",
      "Cost:  [[0.17132362]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1121\n",
      "Cost:  [[0.16833362]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1122\n",
      "Cost:  [[0.1654205]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1123\n",
      "Cost:  [[0.16258212]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1124\n",
      "Cost:  [[0.1598164]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1125\n",
      "Cost:  [[0.15712126]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1126\n",
      "Cost:  [[0.1544947]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1127\n",
      "Cost:  [[0.15193473]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1128\n",
      "Cost:  [[0.14943945]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1129\n",
      "Cost:  [[0.14700696]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1130\n",
      "Cost:  [[0.14463544]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1131\n",
      "Cost:  [[0.1423231]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1132\n",
      "Cost:  [[0.14006821]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1133\n",
      "Cost:  [[0.13786907]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1134\n",
      "Cost:  [[0.13572403]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1135\n",
      "Cost:  [[0.13363151]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1136\n",
      "Cost:  [[0.13158996]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1137\n",
      "Cost:  [[0.12959785]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1138\n",
      "Cost:  [[0.12765375]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1139\n",
      "Cost:  [[0.12575622]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1140\n",
      "Cost:  [[0.1239039]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1141\n",
      "Cost:  [[0.12209545]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1142\n",
      "Cost:  [[0.12032958]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1143\n",
      "Cost:  [[0.11860505]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1144\n",
      "Cost:  [[0.11692063]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1145\n",
      "Cost:  [[0.11527517]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1146\n",
      "Cost:  [[0.11366751]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1147\n",
      "Cost:  [[0.11209657]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1148\n",
      "Cost:  [[0.11056127]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1149\n",
      "Cost:  [[0.10906059]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1150\n",
      "Cost:  [[0.10759353]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1151\n",
      "Cost:  [[0.10615912]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1152\n",
      "Cost:  [[0.10475643]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1153\n",
      "Cost:  [[0.10338456]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1154\n",
      "Cost:  [[0.10204263]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1155\n",
      "Cost:  [[0.10072979]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1156\n",
      "Cost:  [[0.09944523]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1157\n",
      "Cost:  [[0.09818815]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1158\n",
      "Cost:  [[0.09695779]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1159\n",
      "Cost:  [[0.0957534]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1160\n",
      "Cost:  [[0.09457426]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1161\n",
      "Cost:  [[0.09341968]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1162\n",
      "Cost:  [[0.09228898]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1163\n",
      "Cost:  [[0.09118152]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1164\n",
      "Cost:  [[0.09009666]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1165\n",
      "Cost:  [[0.08903379]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1166\n",
      "Cost:  [[0.08799233]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1167\n",
      "Cost:  [[0.08697169]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1168\n",
      "Cost:  [[0.08597133]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1169\n",
      "Cost:  [[0.0849907]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1170\n",
      "Cost:  [[0.0840293]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1171\n",
      "Cost:  [[0.0830866]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1172\n",
      "Cost:  [[0.08216214]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1173\n",
      "Cost:  [[0.08125542]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1174\n",
      "Cost:  [[0.08036601]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1175\n",
      "Cost:  [[0.07949344]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1176\n",
      "Cost:  [[0.0786373]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1177\n",
      "Cost:  [[0.07779716]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1178\n",
      "Cost:  [[0.07697262]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1179\n",
      "Cost:  [[0.07616329]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1180\n",
      "Cost:  [[0.0753688]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1181\n",
      "Cost:  [[0.07458876]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1182\n",
      "Cost:  [[0.07382283]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1183\n",
      "Cost:  [[0.07307065]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1184\n",
      "Cost:  [[0.0723319]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1185\n",
      "Cost:  [[0.07160624]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1186\n",
      "Cost:  [[0.07089336]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1187\n",
      "Cost:  [[0.07019295]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1188\n",
      "Cost:  [[0.06950471]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1189\n",
      "Cost:  [[0.06882836]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1190\n",
      "Cost:  [[0.06816361]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1191\n",
      "Cost:  [[0.0675102]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1192\n",
      "Cost:  [[0.06686784]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1193\n",
      "Cost:  [[0.0662363]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1194\n",
      "Cost:  [[0.06561531]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1195\n",
      "Cost:  [[0.06500464]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1196\n",
      "Cost:  [[0.06440405]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1197\n",
      "Cost:  [[0.06381331]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1198\n",
      "Cost:  [[0.0632322]]\n",
      "Accuracy: 100.0\n",
      "Iteration:  1199\n",
      "Cost:  [[0.06266049]]\n",
      "Accuracy: 100.0\n",
      "Test Accuracy 96.66666666666667\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Sigmoid is used as the activation function\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "#Derivative of the sigmoid function\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x)*(1.0 - sigmoid(x))\n",
    "\n",
    "class NeuralNetwork(object):\n",
    "    \n",
    "    def __init__(self, architecture):\n",
    "        #architecture - numpy array with ith element representing the number of neurons in the ith layer.\n",
    "        \n",
    "        #Initialize the network architecture\n",
    "        self.L = architecture.size - 1 #L corresponds to the last layer of the network.\n",
    "        self.n = architecture #n stores the number of neurons in each layer\n",
    "        #input_size is the number of neurons in the first layer i.e. n[0]\n",
    "        #output_size is the number of neurons in the last layer i.e. n[L]\n",
    "        \n",
    "        #Parameters will store the network parameters, i.e. the weights and biases\n",
    "        self.parameters = {}\n",
    "        \n",
    "        #Initialize the network weights and biases:\n",
    "        for i in range (1, self.L + 1): \n",
    "            #Initialize weights to small random values\n",
    "            self.parameters['W' + str(i)] = np.random.randn(self.n[i], self.n[i - 1]) * 0.01\n",
    "            \n",
    "            #Initialize rest of the parameters to 1\n",
    "            self.parameters['b' + str(i)] = np.ones((self.n[i], 1))\n",
    "            self.parameters['z' + str(i)] = np.ones((self.n[i], 1))\n",
    "            self.parameters['a' + str(i)] = np.ones((self.n[i], 1))\n",
    "        \n",
    "        #As we started the loop from 1, we haven't initialized a[0]:\n",
    "        self.parameters['a0'] = np.ones((self.n[i], 1))\n",
    "        \n",
    "        #Initialize the cost:\n",
    "        self.parameters['C'] = 1\n",
    "        \n",
    "        #Create a dictionary for storing the derivatives:\n",
    "        self.derivatives = {}\n",
    "                    \n",
    "    def forward_propagate(self, X):\n",
    "        #Note that X here, is just one training example\n",
    "        self.parameters['a0'] = X\n",
    "        \n",
    "        #Calculate the activations for every layer l\n",
    "        for l in range(1, self.L + 1):\n",
    "            self.parameters['z' + str(l)] = np.add(np.dot(self.parameters['W' + str(l)], self.parameters['a' + str(l - 1)]), self.parameters['b' + str(l)])\n",
    "            self.parameters['a' + str(l)] = sigmoid(self.parameters['z' + str(l)])\n",
    "        \n",
    "    def compute_cost(self, y):\n",
    "        self.parameters['C'] = -(y*np.log(self.parameters['a' + str(self.L)]) + (1-y)*np.log( 1 - self.parameters['a' + str(self.L)]))\n",
    "    \n",
    "    def compute_derivatives(self, y):\n",
    "        #Partial derivatives of the cost function with respect to z[L], W[L] and b[L]:        \n",
    "        #dzL\n",
    "        self.derivatives['dz' + str(self.L)] = self.parameters['a' + str(self.L)] - y\n",
    "        #dWL\n",
    "        self.derivatives['dW' + str(self.L)] = np.dot(self.derivatives['dz' + str(self.L)], np.transpose(self.parameters['a' + str(self.L - 1)]))\n",
    "        #dbL\n",
    "        self.derivatives['db' + str(self.L)] = self.derivatives['dz' + str(self.L)]\n",
    "\n",
    "        #Partial derivatives of the cost function with respect to z[l], W[l] and b[l]\n",
    "        for l in range(self.L-1, 0, -1):\n",
    "            self.derivatives['dz' + str(l)] = np.dot(np.transpose(self.parameters['W' + str(l + 1)]), self.derivatives['dz' + str(l + 1)])*sigmoid_prime(self.parameters['z' + str(l)])\n",
    "            self.derivatives['dW' + str(l)] = np.dot(self.derivatives['dz' + str(l)], np.transpose(self.parameters['a' + str(l - 1)]))\n",
    "            self.derivatives['db' + str(l)] = self.derivatives['dz' + str(l)]\n",
    "            \n",
    "    def update_parameters(self, alpha):\n",
    "        for l in range(1, self.L+1):\n",
    "            self.parameters['W' + str(l)] -= alpha*self.derivatives['dW' + str(l)]\n",
    "            self.parameters['b' + str(l)] -= alpha*self.derivatives['db' + str(l)]\n",
    "        \n",
    "    def predict(self, x):\n",
    "        self.forward_propagate(x)\n",
    "        return self.parameters['a' + str(self.L)]\n",
    "        \n",
    "    def fit(self, X, Y, num_iter, alpha = 0.01):\n",
    "        for iter in range(0, num_iter):\n",
    "            c = 0 #Stores the cost\n",
    "            n_c = 0 #Stores the number of correct predictions\n",
    "            \n",
    "            for i in range(0, X.shape[0]):\n",
    "              x = X[i].reshape((X[i].size, 1))\n",
    "              y = Y[i]\n",
    "\n",
    "              self.forward_propagate(x)\n",
    "              self.compute_cost(y)\n",
    "              self.compute_derivatives(y)\n",
    "              self.update_parameters(alpha)\n",
    "\n",
    "              c += self.parameters['C'] \n",
    "\n",
    "              y_pred = self.predict(x)\n",
    "              #y_pred is the probability, so to convert it into a class value:\n",
    "              y_pred = (y_pred > 0.5) \n",
    "\n",
    "              if y_pred == y:\n",
    "                  n_c += 1\n",
    "            \n",
    "            c = c/X.shape[0]\n",
    "            print('Iteration: ', iter)\n",
    "            print(\"Cost: \", c)\n",
    "            print(\"Accuracy:\", (n_c/X.shape[0])*100)\n",
    "\n",
    "# #Importing the dataset        \n",
    "data = loadmat(r'D:\\DL\\HW2\\train.mat')\n",
    "test_data = loadmat(r'D:\\DL\\HW2\\test.mat')\n",
    "test_x1, test_x2, test_y = test_data['x1'],test_data['x2'], test_data['y']\n",
    "x1, x2, y = data['x1'],data['x2'], data['y']\n",
    "\n",
    "x=np.hstack([x1,x2])\n",
    "test_c_x=np.hstack([test_x1,test_x2])\n",
    "\n",
    "#Defining the model architecture\n",
    "architecture = np.array([2, 3, 2, 1])\n",
    "\n",
    "#Creating the classifier\n",
    "classifier = NeuralNetwork(architecture)\n",
    "\n",
    "#Training the classifier\n",
    "classifier.fit(x, y, 1200)\n",
    "\n",
    "#Predicting the test set results:\n",
    "n_c = 0\n",
    "for i in range(0, test_c_x.shape[0]):\n",
    "  x = test_c_x[i].reshape((test_c_x[i].size, 1))\n",
    "  y = test_y[i]\n",
    "  y_pred = classifier.predict(x)\n",
    "  y_pred = (y_pred > 0.5)\n",
    "  if y_pred == y:\n",
    "      n_c += 1\n",
    "\n",
    "print(\"Test Accuracy\", (n_c/test_c_x.shape[0])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
